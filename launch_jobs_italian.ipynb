{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1e3de2",
   "metadata": {},
   "source": [
    "### Launch Jobs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7ae843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ads\n",
    "\n",
    "from ads.jobs import DataScienceJob\n",
    "from ads.jobs import DataScienceJobRun\n",
    "from ads.jobs import ScriptRuntime\n",
    "from ads.jobs import Job\n",
    "\n",
    "from ads import set_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6eb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "# project_id = os.environ['PROJECT_OCID']\n",
    "\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d709651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here all the configurations for the JOB\n",
    "#\n",
    "LOG_GROUP_ID = \"ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyazs4l4rzrzsarlej6mqlwlbz6bmnx4adwdlssveam2jaa\"\n",
    "LOG_ID = \"ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdya47httqmxyiew5tkxa6l7gekev2ljpasixuhmp2fa3v5q\"\n",
    "\n",
    "NAMESPACE = \"frqap2zhtzbe\"\n",
    "# the bucket with the custom CONDA env\n",
    "CONDA_BUCKET = \"whisper_jobs_env\"\n",
    "# bucket with code to execute\n",
    "SOURCE_BUCKET = \"whisper_jobs\"\n",
    "\n",
    "CUSTOM_ENV_URI = f\"oci://{CONDA_BUCKET}@{NAMESPACE}/conda_environments/gpu/whisper_env_/1.0/whisper_env_v1_0\"\n",
    "SOURCE_URI = f\"oci://{SOURCE_BUCKET}@{NAMESPACE}/test_atco2.tar.gz\"\n",
    "\n",
    "# the first file to execute\n",
    "RUN_ENTRYPOINT = \"train.sh\"\n",
    "\n",
    "# SHAPE_NAME = \"VM.Standard2.4\"\n",
    "# SHAPE_NAME = \"VM.GPU2.1\"\n",
    "SHAPE_NAME = \"VM.GPU.A10.2\"\n",
    "# in GB\n",
    "STORAGE_SIZE = 2000\n",
    "\n",
    "JOBS_NAME = \"job_atco2_007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eb76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Specify the Infrastructure requested\n",
    "# VM Shape, logging\n",
    "# network is taken from NB session\n",
    "\n",
    "# you need to provide the OCID for LogGroup and Log\n",
    "infrastructure = (\n",
    "    DataScienceJob()\n",
    "    .with_shape_name(SHAPE_NAME)\n",
    "    .with_block_storage_size(STORAGE_SIZE)\n",
    "    .with_log_group_id(LOG_GROUP_ID)\n",
    "    .with_log_id(LOG_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0f2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the runtime and conda and env \n",
    "runtime = (\n",
    "    ScriptRuntime()\n",
    "    .with_source(SOURCE_URI)\n",
    "    .with_custom_conda(CUSTOM_ENV_URI)\n",
    "    .with_environment_variable(JOB_RUN_ENTRYPOINT=RUN_ENTRYPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc8b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the JOB\n",
    "job = (\n",
    "    Job(name=JOBS_NAME)\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_runtime(runtime)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff59a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kind: job\n",
       "spec:\n",
       "  id: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyawfbeauoxq3to4c7iweu33dq2jrc5h2thle6jmfpjvgfq\n",
       "  infrastructure:\n",
       "    kind: infrastructure\n",
       "    spec:\n",
       "      blockStorageSize: 2000\n",
       "      compartmentId: ocid1.compartment.oc1..aaaaaaaag2cpni5qj6li5ny6ehuahhepbpveopobooayqfeudqygdtfe6h3a\n",
       "      displayName: job_atco2_007\n",
       "      jobInfrastructureType: STANDALONE\n",
       "      jobType: DEFAULT\n",
       "      logGroupId: ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyazs4l4rzrzsarlej6mqlwlbz6bmnx4adwdlssveam2jaa\n",
       "      logId: ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdya47httqmxyiew5tkxa6l7gekev2ljpasixuhmp2fa3v5q\n",
       "      projectId: ocid1.datascienceproject.oc1.eu-frankfurt-1.amaaaaaangencdyasybymsgwfmwo7ukyjs6kdl573kpxnb5rgy52c5irb5pq\n",
       "      shapeName: VM.GPU.A10.2\n",
       "      subnetId: ocid1.subnet.oc1.eu-frankfurt-1.aaaaaaaaijgqblnhpqle2zorl75qli23wre5eboqjtystagdgun4qwdxj4aq\n",
       "    type: dataScienceJob\n",
       "  name: job_atco2_007\n",
       "  runtime:\n",
       "    kind: runtime\n",
       "    spec:\n",
       "      conda:\n",
       "        type: published\n",
       "        uri: oci://whisper_jobs_env@frqap2zhtzbe/conda_environments/gpu/whisper_env_/1.0/whisper_env_v1_0\n",
       "      env:\n",
       "      - name: JOB_RUN_ENTRYPOINT\n",
       "        value: train.sh\n",
       "      scriptPathURI: oci://whisper_jobs@frqap2zhtzbe/test_atco2.tar.gz\n",
       "    type: script"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the JOB\n",
    "job.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fcc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the job run by id\n",
    "# JOB_RUN_OCID = \"ocid1.datasciencejobrun.oc1.eu-frankfurt-1.amaaaaaangencdyais5w2gkzbqbwqeftps6raay65ymhg46hltw3vlokij3q\"\n",
    "\n",
    "# job_run = DataScienceJobRun.from_ocid(JOB_RUN_OCID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a7312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28becd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job OCID: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyawfbeauoxq3to4c7iweu33dq2jrc5h2thle6jmfpjvgfq\n",
      "Job Run OCID: ocid1.datasciencejobrun.oc1.eu-frankfurt-1.amaaaaaangencdyasd7tjtnzu5ennlv3mogdzvmvij52fqvz7lhfbur7m4va\n",
      "2023-09-11 09:16:27 - Job Run ACCEPTED\n",
      "2023-09-11 09:16:43 - Job Run ACCEPTED, Infrastructure provisioning.\n",
      "2023-09-11 09:17:55 - Job Run ACCEPTED, Infrastructure provisioned.\n",
      "2023-09-11 09:18:29 - Job Run ACCEPTED, Job run bootstrap starting.\n",
      "2023-09-11 09:21:58 - Job Run ACCEPTED, Job run bootstrap complete. Artifact execution starting.\n",
      "2023-09-11 09:22:11 - Job Run IN_PROGRESS, Job run artifact execution in progress.\n",
      "2023-09-11 09:21:58 - *****************************************\n",
      "2023-09-11 09:21:58 - WARNING:torch.distributed.run:\n",
      "2023-09-11 09:21:58 - *****************************************\n",
      "2023-09-11 09:21:58 - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "2023-09-11 09:21:58 - Fontconfig error: Cannot load default config file: No such file: (null)\n",
      "2023-09-11 09:21:58 - Fontconfig error: Cannot load default config file: No such file: (null)\n",
      "Downloading metadata: 100% 806/806 [00:00<00:00, 1.19MB/s]\n",
      "Downloading metadata: 100% 806/806 [00:00<00:00, 1.23MB/s]\n",
      "Downloading readme: 100% 220/220 [00:00<00:00, 403kB/s]\n",
      "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  10% 10.7M/113M [00:00<00:00, 107MB/s]\u001b[A\n",
      "Downloading data:  19% 21.8M/113M [00:00<00:00, 109MB/s]\u001b[A\n",
      "Downloading data:  29% 32.9M/113M [00:00<00:00, 110MB/s]\u001b[A\n",
      "Downloading data:  39% 44.0M/113M [00:00<00:00, 110MB/s]\u001b[A\n",
      "Downloading data:  49% 55.1M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data:  59% 66.3M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data:  69% 77.4M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data:  79% 88.6M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data:  88% 99.7M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data: 100% 113M/113M [00:01<00:00, 111MB/s] \u001b[A\n",
      "Downloading data files:  50% 1/2 [00:01<00:01,  1.32s/it]\n",
      "Downloading data:   0% 0.00/13.2M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 13.2M/13.2M [00:00<00:00, 105MB/s]\u001b[A\n",
      "Downloading data files: 100% 2/2 [00:01<00:00,  1.16it/s]\n",
      "Extracting data files: 100% 2/2 [00:00<00:00, 2385.16it/s]\n",
      "Downloading (…)lve/main/config.json: 100% 1.99k/1.99k [00:00<00:00, 1.11MB/s]\n",
      "2023-09-11 09:22:07 - [INFO|configuration_utils.py:669] 2023-09-11 09:22:07,678 >> loading configuration file config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/config.json\n",
      "2023-09-11 09:22:07 -   \"apply_spec_augment\": false,\n",
      "2023-09-11 09:22:07 -   \"activation_function\": \"gelu\",\n",
      "2023-09-11 09:22:07 -   \"activation_dropout\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"_name_or_path\": \"openai/whisper-medium\",\n",
      "2023-09-11 09:22:07 - [INFO|configuration_utils.py:725] 2023-09-11 09:22:07,682 >> Model config WhisperConfig {\n",
      "2023-09-11 09:22:07 -   \"begin_suppress_tokens\": [\n",
      "2023-09-11 09:22:07 -   \"attention_dropout\": 0.0,\n",
      "2023-09-11 09:22:07 -   ],\n",
      "2023-09-11 09:22:07 -     \"WhisperForConditionalGeneration\"\n",
      "2023-09-11 09:22:07 -   \"architectures\": [\n",
      "2023-09-11 09:22:07 -   \"classifier_proj_size\": 256,\n",
      "2023-09-11 09:22:07 -   \"bos_token_id\": 50257,\n",
      "2023-09-11 09:22:07 -   ],\n",
      "2023-09-11 09:22:07 -     50257\n",
      "2023-09-11 09:22:07 -     220,\n",
      "2023-09-11 09:22:07 -   \"decoder_layers\": 24,\n",
      "2023-09-11 09:22:07 -   \"decoder_layerdrop\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"decoder_ffn_dim\": 4096,\n",
      "2023-09-11 09:22:07 -   \"decoder_attention_heads\": 16,\n",
      "2023-09-11 09:22:07 -   \"d_model\": 1024,\n",
      "2023-09-11 09:22:07 -   \"encoder_layers\": 24,\n",
      "2023-09-11 09:22:07 -   \"encoder_layerdrop\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"encoder_ffn_dim\": 4096,\n",
      "2023-09-11 09:22:07 -   \"encoder_attention_heads\": 16,\n",
      "2023-09-11 09:22:07 -   \"dropout\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-11 09:22:07 -       50259\n",
      "2023-09-11 09:22:07 -       1,\n",
      "2023-09-11 09:22:07 -     [\n",
      "2023-09-11 09:22:07 -   \"forced_decoder_ids\": [\n",
      "2023-09-11 09:22:07 -   \"eos_token_id\": 50257,\n",
      "2023-09-11 09:22:07 -       3,\n",
      "2023-09-11 09:22:07 -     [\n",
      "2023-09-11 09:22:07 -     ],\n",
      "2023-09-11 09:22:07 -       50359\n",
      "2023-09-11 09:22:07 -       2,\n",
      "2023-09-11 09:22:07 -     [\n",
      "2023-09-11 09:22:07 -     ],\n",
      "2023-09-11 09:22:07 -   \"is_encoder_decoder\": true,\n",
      "2023-09-11 09:22:07 -   \"init_std\": 0.02,\n",
      "2023-09-11 09:22:07 -   ],\n",
      "2023-09-11 09:22:07 -     ]\n",
      "2023-09-11 09:22:07 -       50363\n",
      "2023-09-11 09:22:07 -   \"mask_time_prob\": 0.05,\n",
      "2023-09-11 09:22:07 -   \"mask_time_min_masks\": 2,\n",
      "2023-09-11 09:22:07 -   \"mask_time_length\": 10,\n",
      "2023-09-11 09:22:07 -   \"mask_feature_prob\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"mask_feature_min_masks\": 0,\n",
      "2023-09-11 09:22:07 -   \"mask_feature_length\": 10,\n",
      "2023-09-11 09:22:07 -   \"num_hidden_layers\": 24,\n",
      "2023-09-11 09:22:07 -   \"model_type\": \"whisper\",\n",
      "2023-09-11 09:22:07 -   \"max_target_positions\": 448,\n",
      "2023-09-11 09:22:07 -   \"max_source_positions\": 1500,\n",
      "2023-09-11 09:22:07 -   \"max_length\": 448,\n",
      "2023-09-11 09:22:07 -     7,\n",
      "2023-09-11 09:22:07 -     2,\n",
      "2023-09-11 09:22:07 -     1,\n",
      "2023-09-11 09:22:07 -   \"suppress_tokens\": [\n",
      "2023-09-11 09:22:07 -   \"scale_embedding\": false,\n",
      "2023-09-11 09:22:07 -   \"pad_token_id\": 50257,\n",
      "2023-09-11 09:22:07 -   \"num_mel_bins\": 80,\n",
      "2023-09-11 09:22:07 -     25,\n",
      "2023-09-11 09:22:07 -     14,\n",
      "2023-09-11 09:22:07 -     10,\n",
      "2023-09-11 09:22:07 -     9,\n",
      "2023-09-11 09:22:07 -     8,\n",
      "2023-09-11 09:22:07 -     58,\n",
      "2023-09-11 09:22:07 -     31,\n",
      "2023-09-11 09:22:07 -     29,\n",
      "2023-09-11 09:22:07 -     28,\n",
      "2023-09-11 09:22:07 -     27,\n",
      "2023-09-11 09:22:07 -     26,\n",
      "2023-09-11 09:22:07 -     63,\n",
      "2023-09-11 09:22:07 -     62,\n",
      "2023-09-11 09:22:07 -     61,\n",
      "2023-09-11 09:22:07 -     60,\n",
      "2023-09-11 09:22:07 -     59,\n",
      "2023-09-11 09:22:07 -     503,\n",
      "2023-09-11 09:22:07 -     359,\n",
      "2023-09-11 09:22:07 -     93,\n",
      "2023-09-11 09:22:07 -     92,\n",
      "2023-09-11 09:22:07 -     91,\n",
      "2023-09-11 09:22:07 -     90,\n",
      "2023-09-11 09:22:07 -     918,\n",
      "2023-09-11 09:22:07 -     902,\n",
      "2023-09-11 09:22:07 -     893,\n",
      "2023-09-11 09:22:07 -     873,\n",
      "2023-09-11 09:22:07 -     542,\n",
      "2023-09-11 09:22:07 -     522,\n",
      "2023-09-11 09:22:07 -     2627,\n",
      "2023-09-11 09:22:07 -     2460,\n",
      "2023-09-11 09:22:07 -     1982,\n",
      "2023-09-11 09:22:07 -     1853,\n",
      "2023-09-11 09:22:07 -     1350,\n",
      "2023-09-11 09:22:07 -     931,\n",
      "2023-09-11 09:22:07 -     922,\n",
      "2023-09-11 09:22:07 -     3846,\n",
      "2023-09-11 09:22:07 -     3536,\n",
      "2023-09-11 09:22:07 -     3268,\n",
      "2023-09-11 09:22:07 -     3253,\n",
      "2023-09-11 09:22:07 -     3246,\n",
      "2023-09-11 09:22:07 -     7273,\n",
      "2023-09-11 09:22:07 -     6647,\n",
      "2023-09-11 09:22:07 -     6585,\n",
      "2023-09-11 09:22:07 -     4667,\n",
      "2023-09-11 09:22:07 -     4183,\n",
      "2023-09-11 09:22:07 -     3961,\n",
      "2023-09-11 09:22:07 -     11938,\n",
      "2023-09-11 09:22:07 -     10929,\n",
      "2023-09-11 09:22:07 -     10428,\n",
      "2023-09-11 09:22:07 -     9383,\n",
      "2023-09-11 09:22:07 -     9061,\n",
      "2023-09-11 09:22:07 -     14157,\n",
      "2023-09-11 09:22:07 -     13793,\n",
      "2023-09-11 09:22:07 -     12562,\n",
      "2023-09-11 09:22:07 -     12331,\n",
      "2023-09-11 09:22:07 -     12033,\n",
      "2023-09-11 09:22:07 -     18956,\n",
      "2023-09-11 09:22:07 -     18362,\n",
      "2023-09-11 09:22:07 -     16604,\n",
      "2023-09-11 09:22:07 -     16553,\n",
      "2023-09-11 09:22:07 -     15618,\n",
      "2023-09-11 09:22:07 -     15265,\n",
      "2023-09-11 09:22:07 -     14635,\n",
      "2023-09-11 09:22:07 -     26161,\n",
      "2023-09-11 09:22:07 -     26130,\n",
      "2023-09-11 09:22:07 -     22520,\n",
      "2023-09-11 09:22:07 -     21675,\n",
      "2023-09-11 09:22:07 -     20075,\n",
      "2023-09-11 09:22:07 -     32470,\n",
      "2023-09-11 09:22:07 -     32302,\n",
      "2023-09-11 09:22:07 -     31650,\n",
      "2023-09-11 09:22:07 -     29464,\n",
      "2023-09-11 09:22:07 -     28279,\n",
      "2023-09-11 09:22:07 -     26435,\n",
      "2023-09-11 09:22:07 -     50254,\n",
      "2023-09-11 09:22:07 -     49870,\n",
      "2023-09-11 09:22:07 -     47425,\n",
      "2023-09-11 09:22:07 -     42863,\n",
      "2023-09-11 09:22:07 -     36865,\n",
      "2023-09-11 09:22:07 -     50359,\n",
      "2023-09-11 09:22:07 -     50358,\n",
      "2023-09-11 09:22:07 -     50258,\n",
      "2023-09-11 09:22:07 -   ],\n",
      "2023-09-11 09:22:07 -     50362\n",
      "2023-09-11 09:22:07 -     50361,\n",
      "2023-09-11 09:22:07 -     50360,\n",
      "2023-09-11 09:22:07 -   \"vocab_size\": 51865\n",
      "2023-09-11 09:22:07 -   \"use_weighted_layer_sum\": false,\n",
      "2023-09-11 09:22:07 -   \"use_cache\": true,\n",
      "2023-09-11 09:22:07 -   \"transformers_version\": \"4.30.2\",\n",
      "2023-09-11 09:22:07 -   \"torch_dtype\": \"float32\",\n",
      "2023-09-11 09:22:07 - \n",
      "2023-09-11 09:22:07 - }\n",
      "Downloading (…)rocessor_config.json: 100% 185k/185k [00:00<00:00, 2.06MB/s]\n",
      "2023-09-11 09:22:07 - [INFO|feature_extraction_utils.py:477] 2023-09-11 09:22:07,985 >> loading configuration file preprocessor_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/preprocessor_config.json\n",
      "2023-09-11 09:22:07 - [INFO|feature_extraction_utils.py:519] 2023-09-11 09:22:07,987 >> Feature extractor WhisperFeatureExtractor {\n",
      "2023-09-11 09:22:07 -   \"nb_max_frames\": 3000,\n",
      "2023-09-11 09:22:07 -   \"n_samples\": 480000,\n",
      "2023-09-11 09:22:07 -   \"n_fft\": 400,\n",
      "2023-09-11 09:22:07 -   \"hop_length\": 160,\n",
      "2023-09-11 09:22:07 -   \"feature_size\": 80,\n",
      "2023-09-11 09:22:07 -   \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "2023-09-11 09:22:07 -   \"chunk_length\": 30,\n",
      "2023-09-11 09:22:07 - }\n",
      "2023-09-11 09:22:07 -   \"sampling_rate\": 16000\n",
      "2023-09-11 09:22:07 -   \"return_attention_mask\": false,\n",
      "2023-09-11 09:22:07 -   \"processor_class\": \"WhisperProcessor\",\n",
      "2023-09-11 09:22:07 -   \"padding_value\": 0.0,\n",
      "2023-09-11 09:22:07 -   \"padding_side\": \"right\",\n",
      "2023-09-11 09:22:07 - \n",
      "Downloading (…)okenizer_config.json: 100% 805/805 [00:00<00:00, 780kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100% 836k/836k [00:00<00:00, 50.0MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100% 2.48M/2.48M [00:00<00:00, 9.05MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100% 494k/494k [00:00<00:00, 64.3MB/s]\n",
      "Downloading (…)main/normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 590kB/s]\n",
      "Downloading (…)in/added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 40.1MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100% 2.08k/2.08k [00:00<00:00, 3.18MB/s]\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file merges.txt from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/merges.txt\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file tokenizer.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/tokenizer.json\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,959 >> loading file vocab.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/vocab.json\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file tokenizer_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/tokenizer_config.json\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file special_tokens_map.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/special_tokens_map.json\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file added_tokens.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/added_tokens.json\n",
      "2023-09-11 09:22:09 - [INFO|tokenization_utils_base.py:1823] 2023-09-11 09:22:09,960 >> loading file normalizer.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/normalizer.json\n",
      "Downloading model.safetensors: 100% 3.06G/3.06G [00:11<00:00, 256MB/s]\n",
      "2023-09-11 09:22:23 - [INFO|modeling_utils.py:2578] 2023-09-11 09:22:23,359 >> loading weights file model.safetensors from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/model.safetensors\n",
      "2023-09-11 09:22:23 -     220,\n",
      "2023-09-11 09:22:23 -   \"begin_suppress_tokens\": [\n",
      "2023-09-11 09:22:23 -   \"_from_model_config\": true,\n",
      "2023-09-11 09:22:23 - [INFO|configuration_utils.py:577] 2023-09-11 09:22:23,490 >> Generate config GenerationConfig {\n",
      "2023-09-11 09:22:23 -   \"max_length\": 448,\n",
      "2023-09-11 09:22:23 -   \"eos_token_id\": 50257,\n",
      "2023-09-11 09:22:23 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-11 09:22:23 -   \"bos_token_id\": 50257,\n",
      "2023-09-11 09:22:23 -   ],\n",
      "2023-09-11 09:22:23 -     50257\n",
      "2023-09-11 09:22:23 - \n",
      "2023-09-11 09:22:23 - }\n",
      "2023-09-11 09:22:23 -   \"transformers_version\": \"4.30.2\"\n",
      "2023-09-11 09:22:23 -   \"pad_token_id\": 50257,\n",
      "2023-09-11 09:22:53 - 09/11/2023 09:22:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3a182f4deb3e65ad.arrow\n",
      "2023-09-11 09:22:53 - 09/11/2023 09:22:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-06cd434167932e0d.arrow\n",
      "2023-09-11 09:22:53 - 09/11/2023 09:22:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-75fbe15b5bdc29a8.arrow\n",
      "2023-09-11 09:22:53 - 09/11/2023 09:22:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-1a198c78df00ed13.arrow\n",
      "2023-09-11 09:22:55 - \n",
      "2023-09-11 09:22:55 -   warnings.warn(\n",
      "2023-09-11 09:22:55 - 09/11/2023 09:22:55 - WARNING - py.warnings - /home/datascience/conda/whisper_env_v1_0/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "2023-09-11 09:22:55 - \n",
      "2023-09-11 09:22:55 -   warnings.warn(\n",
      "2023-09-11 09:22:55 - 09/11/2023 09:22:55 - WARNING - py.warnings - /home/datascience/conda/whisper_env_v1_0/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "2023-09-11 09:22:55 - To disable this warning, you can either:\n",
      "2023-09-11 09:22:55 - huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "2023-09-11 09:22:55 - \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-09-11 09:22:55 - \t- Avoid using `tokenizers` before the fork if possible\n",
      "2023-09-11 09:22:55 - To disable this warning, you can either:\n",
      "2023-09-11 09:22:55 - huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "2023-09-11 09:22:55 - \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-09-11 09:22:55 - \t- Avoid using `tokenizers` before the fork if possible\n",
      "2023-09-11 09:22:02 - Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "2023-09-11 09:22:02 - Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "2023-09-11 09:22:02 - Login successful\n",
      "2023-09-11 09:22:02 - Your token has been saved to /home/datascience/.cache/huggingface/token\n",
      "2023-09-11 09:22:02 - Token is valid (permission: write).\n",
      "2023-09-11 09:22:02 - Token is valid (permission: write).\n",
      "2023-09-11 09:22:02 - Login successful\n",
      "2023-09-11 09:22:02 - Your token has been saved to /home/datascience/.cache/huggingface/token\n",
      "2023-09-11 09:22:02 - 09/11/2023 09:22:02 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "2023-09-11 09:22:02 - 09/11/2023 09:22:02 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "2023-09-11 09:22:02 - adam_epsilon=1e-08,\n",
      "2023-09-11 09:22:02 - adam_beta2=0.999,\n",
      "2023-09-11 09:22:02 - adam_beta1=0.9,\n",
      "2023-09-11 09:22:02 - adafactor=False,\n",
      "2023-09-11 09:22:02 - _n_gpu=1,\n",
      "2023-09-11 09:22:02 - auto_find_batch_size=False,\n",
      "2023-09-11 09:22:02 - dataloader_pin_memory=True,\n",
      "2023-09-11 09:22:02 - dataloader_num_workers=0,\n",
      "2023-09-11 09:22:02 - dataloader_drop_last=False,\n",
      "2023-09-11 09:22:02 - data_seed=None,\n",
      "2023-09-11 09:22:02 - bf16_full_eval=False,\n",
      "2023-09-11 09:22:02 - bf16=False,\n",
      "2023-09-11 09:22:02 - deepspeed=None,\n",
      "2023-09-11 09:22:02 - debug=[],\n",
      "2023-09-11 09:22:02 - ddp_timeout=1800,\n",
      "2023-09-11 09:22:02 - ddp_find_unused_parameters=None,\n",
      "2023-09-11 09:22:02 - ddp_bucket_cap_mb=None,\n",
      "2023-09-11 09:22:02 - ddp_backend=None,\n",
      "2023-09-11 09:22:02 - evaluation_strategy=steps,\n",
      "2023-09-11 09:22:02 - eval_steps=50,\n",
      "2023-09-11 09:22:02 - eval_delay=0,\n",
      "2023-09-11 09:22:02 - eval_accumulation_steps=None,\n",
      "2023-09-11 09:22:02 - do_train=True,\n",
      "2023-09-11 09:22:02 - do_predict=False,\n",
      "2023-09-11 09:22:02 - do_eval=True,\n",
      "2023-09-11 09:22:02 - disable_tqdm=False,\n",
      "2023-09-11 09:22:02 - fsdp_min_num_params=0,\n",
      "2023-09-11 09:22:02 - fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "2023-09-11 09:22:02 - fsdp=[],\n",
      "2023-09-11 09:22:02 - fp16_opt_level=O1,\n",
      "2023-09-11 09:22:02 - fp16_full_eval=False,\n",
      "2023-09-11 09:22:02 - fp16_backend=auto,\n",
      "2023-09-11 09:22:02 - fp16=True,\n",
      "2023-09-11 09:22:02 - generation_max_length=225,\n",
      "2023-09-11 09:22:02 - generation_config=None,\n",
      "2023-09-11 09:22:02 - full_determinism=False,\n",
      "2023-09-11 09:22:02 - fsdp_transformer_layer_cls_to_wrap=None,\n",
      "2023-09-11 09:22:02 - half_precision_backend=auto,\n",
      "2023-09-11 09:22:02 - group_by_length=False,\n",
      "2023-09-11 09:22:02 - greater_is_better=None,\n",
      "2023-09-11 09:22:02 - gradient_checkpointing=True,\n",
      "2023-09-11 09:22:02 - gradient_accumulation_steps=8,\n",
      "2023-09-11 09:22:02 - generation_num_beams=None,\n",
      "2023-09-11 09:22:02 - learning_rate=1e-05,\n",
      "2023-09-11 09:22:02 - label_smoothing_factor=0.0,\n",
      "2023-09-11 09:22:02 - label_names=None,\n",
      "2023-09-11 09:22:02 - jit_mode_eval=False,\n",
      "2023-09-11 09:22:02 - include_inputs_for_metrics=False,\n",
      "2023-09-11 09:22:02 - ignore_data_skip=False,\n",
      "2023-09-11 09:22:02 - hub_token=<HUB_TOKEN>,\n",
      "2023-09-11 09:22:02 - hub_strategy=every_save,\n",
      "2023-09-11 09:22:02 - hub_private_repo=False,\n",
      "2023-09-11 09:22:02 - hub_model_id=None,\n",
      "2023-09-11 09:22:02 - logging_dir=/mnt/output/runs/Sep11_09-22-02_ea7d25f61b47,\n",
      "2023-09-11 09:22:02 - log_on_each_node=True,\n",
      "2023-09-11 09:22:02 - log_level_replica=warning,\n",
      "2023-09-11 09:22:02 - log_level=passive,\n",
      "2023-09-11 09:22:02 - local_rank=0,\n",
      "2023-09-11 09:22:02 - load_best_model_at_end=False,\n",
      "2023-09-11 09:22:02 - length_column_name=input_length,\n",
      "2023-09-11 09:22:02 - metric_for_best_model=None,\n",
      "2023-09-11 09:22:02 - max_steps=1000,\n",
      "2023-09-11 09:22:02 - max_grad_norm=1.0,\n",
      "2023-09-11 09:22:02 - lr_scheduler_type=linear,\n",
      "2023-09-11 09:22:02 - logging_strategy=steps,\n",
      "2023-09-11 09:22:02 - logging_steps=25,\n",
      "2023-09-11 09:22:02 - logging_nan_inf_filter=True,\n",
      "2023-09-11 09:22:02 - logging_first_step=False,\n",
      "2023-09-11 09:22:02 - per_device_train_batch_size=2,\n",
      "2023-09-11 09:22:02 - per_device_eval_batch_size=8,\n",
      "2023-09-11 09:22:02 - past_index=-1,\n",
      "2023-09-11 09:22:02 - overwrite_output_dir=True,\n",
      "2023-09-11 09:22:02 - output_dir=/mnt/output,\n",
      "2023-09-11 09:22:02 - optim_args=None,\n",
      "2023-09-11 09:22:02 - optim=adamw_hf,\n",
      "2023-09-11 09:22:02 - num_train_epochs=3.0,\n",
      "2023-09-11 09:22:02 - no_cuda=False,\n",
      "2023-09-11 09:22:02 - mp_parameters=,\n",
      "2023-09-11 09:22:02 - resume_from_checkpoint=None,\n",
      "2023-09-11 09:22:02 - report_to=['mlflow', 'tensorboard'],\n",
      "2023-09-11 09:22:02 - remove_unused_columns=True,\n",
      "2023-09-11 09:22:02 - ray_scope=last,\n",
      "2023-09-11 09:22:02 - push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "2023-09-11 09:22:02 - push_to_hub_organization=None,\n",
      "2023-09-11 09:22:02 - push_to_hub_model_id=None,\n",
      "2023-09-11 09:22:02 - push_to_hub=False,\n",
      "2023-09-11 09:22:02 - prediction_loss_only=False,\n",
      "2023-09-11 09:22:02 - predict_with_generate=True,\n",
      "2023-09-11 09:22:02 - seed=42,\n",
      "2023-09-11 09:22:02 - save_total_limit=None,\n",
      "2023-09-11 09:22:02 - save_strategy=steps,\n",
      "2023-09-11 09:22:02 - save_steps=50,\n",
      "2023-09-11 09:22:02 - save_safetensors=False,\n",
      "2023-09-11 09:22:02 - save_on_each_node=False,\n",
      "2023-09-11 09:22:02 - run_name=/mnt/output,\n",
      "2023-09-11 09:22:02 - torch_compile_backend=None,\n",
      "2023-09-11 09:22:02 - torch_compile=False,\n",
      "2023-09-11 09:22:02 - tf32=None,\n",
      "2023-09-11 09:22:02 - sortish_sampler=False,\n",
      "2023-09-11 09:22:02 - skip_memory_metrics=True,\n",
      "2023-09-11 09:22:02 - sharded_ddp=[],\n",
      "2023-09-11 09:22:02 - tpu_num_cores=None,\n",
      "2023-09-11 09:22:02 - tpu_metrics_debug=False,\n",
      "2023-09-11 09:22:02 - torchdynamo=None,\n",
      "2023-09-11 09:22:02 - torch_compile_mode=None,\n",
      "2023-09-11 09:22:02 - _n_gpu=1,\n",
      "2023-09-11 09:22:02 - 09/11/2023 09:22:02 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "2023-09-11 09:22:02 - )\n",
      "2023-09-11 09:22:02 - xpu_backend=None,\n",
      "2023-09-11 09:22:02 - weight_decay=0.0,\n",
      "2023-09-11 09:22:02 - warmup_steps=200,\n",
      "2023-09-11 09:22:02 - warmup_ratio=0.0,\n",
      "2023-09-11 09:22:02 - use_mps_device=False,\n",
      "2023-09-11 09:22:02 - use_legacy_prediction_loop=False,\n",
      "2023-09-11 09:22:02 - use_ipex=False,\n",
      "2023-09-11 09:22:02 - data_seed=None,\n",
      "2023-09-11 09:22:02 - bf16_full_eval=False,\n",
      "2023-09-11 09:22:02 - bf16=False,\n",
      "2023-09-11 09:22:02 - auto_find_batch_size=False,\n",
      "2023-09-11 09:22:02 - adam_epsilon=1e-08,\n",
      "2023-09-11 09:22:02 - adam_beta2=0.999,\n",
      "2023-09-11 09:22:02 - adam_beta1=0.9,\n",
      "2023-09-11 09:22:02 - adafactor=False,\n",
      "2023-09-11 09:22:02 - disable_tqdm=False,\n",
      "2023-09-11 09:22:02 - deepspeed=None,\n",
      "2023-09-11 09:22:02 - debug=[],\n",
      "2023-09-11 09:22:02 - ddp_timeout=1800,\n",
      "2023-09-11 09:22:02 - ddp_find_unused_parameters=None,\n",
      "2023-09-11 09:22:02 - ddp_bucket_cap_mb=None,\n",
      "2023-09-11 09:22:02 - ddp_backend=None,\n",
      "2023-09-11 09:22:02 - dataloader_pin_memory=True,\n",
      "2023-09-11 09:22:02 - dataloader_num_workers=0,\n",
      "2023-09-11 09:22:02 - dataloader_drop_last=False,\n",
      "2023-09-11 09:22:02 - fp16_backend=auto,\n",
      "2023-09-11 09:22:02 - fp16=True,\n",
      "2023-09-11 09:22:02 - evaluation_strategy=steps,\n",
      "2023-09-11 09:22:02 - eval_steps=50,\n",
      "2023-09-11 09:22:02 - eval_delay=0,\n",
      "2023-09-11 09:22:02 - eval_accumulation_steps=None,\n",
      "2023-09-11 09:22:02 - do_train=True,\n",
      "2023-09-11 09:22:02 - do_predict=False,\n",
      "2023-09-11 09:22:02 - do_eval=True,\n",
      "2023-09-11 09:22:02 - generation_config=None,\n",
      "2023-09-11 09:22:02 - full_determinism=False,\n",
      "2023-09-11 09:22:02 - fsdp_transformer_layer_cls_to_wrap=None,\n",
      "2023-09-11 09:22:02 - fsdp_min_num_params=0,\n",
      "2023-09-11 09:22:02 - fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "2023-09-11 09:22:02 - fsdp=[],\n",
      "2023-09-11 09:22:02 - fp16_opt_level=O1,\n",
      "2023-09-11 09:22:02 - fp16_full_eval=False,\n",
      "2023-09-11 09:22:02 - half_precision_backend=auto,\n",
      "2023-09-11 09:22:02 - group_by_length=False,\n",
      "2023-09-11 09:22:02 - greater_is_better=None,\n",
      "2023-09-11 09:22:02 - gradient_checkpointing=True,\n",
      "2023-09-11 09:22:02 - gradient_accumulation_steps=8,\n",
      "2023-09-11 09:22:02 - generation_num_beams=None,\n",
      "2023-09-11 09:22:02 - generation_max_length=225,\n",
      "2023-09-11 09:22:02 - learning_rate=1e-05,\n",
      "2023-09-11 09:22:02 - label_smoothing_factor=0.0,\n",
      "2023-09-11 09:22:02 - label_names=None,\n",
      "2023-09-11 09:22:02 - jit_mode_eval=False,\n",
      "2023-09-11 09:22:02 - include_inputs_for_metrics=False,\n",
      "2023-09-11 09:22:02 - ignore_data_skip=False,\n",
      "2023-09-11 09:22:02 - hub_token=<HUB_TOKEN>,\n",
      "2023-09-11 09:22:02 - hub_strategy=every_save,\n",
      "2023-09-11 09:22:02 - hub_private_repo=False,\n",
      "2023-09-11 09:22:02 - hub_model_id=None,\n",
      "2023-09-11 09:22:02 - logging_first_step=False,\n",
      "2023-09-11 09:22:02 - logging_dir=/mnt/output/runs/Sep11_09-22-02_ea7d25f61b47,\n",
      "2023-09-11 09:22:02 - log_on_each_node=True,\n",
      "2023-09-11 09:22:02 - log_level_replica=warning,\n",
      "2023-09-11 09:22:02 - log_level=passive,\n",
      "2023-09-11 09:22:02 - local_rank=0,\n",
      "2023-09-11 09:22:02 - load_best_model_at_end=False,\n",
      "2023-09-11 09:22:02 - length_column_name=input_length,\n",
      "2023-09-11 09:22:02 - metric_for_best_model=None,\n",
      "2023-09-11 09:22:02 - max_steps=1000,\n",
      "2023-09-11 09:22:02 - max_grad_norm=1.0,\n",
      "2023-09-11 09:22:02 - lr_scheduler_type=linear,\n",
      "2023-09-11 09:22:02 - logging_strategy=steps,\n",
      "2023-09-11 09:22:02 - logging_steps=25,\n",
      "2023-09-11 09:22:02 - logging_nan_inf_filter=True,\n",
      "2023-09-11 09:22:02 - overwrite_output_dir=True,\n",
      "2023-09-11 09:22:02 - output_dir=/mnt/output,\n",
      "2023-09-11 09:22:02 - optim_args=None,\n",
      "2023-09-11 09:22:02 - optim=adamw_hf,\n",
      "2023-09-11 09:22:02 - num_train_epochs=3.0,\n",
      "2023-09-11 09:22:02 - no_cuda=False,\n",
      "2023-09-11 09:22:02 - mp_parameters=,\n",
      "2023-09-11 09:22:02 - push_to_hub=False,\n",
      "2023-09-11 09:22:02 - prediction_loss_only=False,\n",
      "2023-09-11 09:22:02 - predict_with_generate=True,\n",
      "2023-09-11 09:22:02 - per_device_train_batch_size=2,\n",
      "2023-09-11 09:22:02 - per_device_eval_batch_size=8,\n",
      "2023-09-11 09:22:02 - past_index=-1,\n",
      "2023-09-11 09:22:02 - save_safetensors=False,\n",
      "2023-09-11 09:22:02 - save_on_each_node=False,\n",
      "2023-09-11 09:22:02 - run_name=/mnt/output,\n",
      "2023-09-11 09:22:02 - resume_from_checkpoint=None,\n",
      "2023-09-11 09:22:02 - report_to=['mlflow', 'tensorboard'],\n",
      "2023-09-11 09:22:02 - remove_unused_columns=True,\n",
      "2023-09-11 09:22:02 - ray_scope=last,\n",
      "2023-09-11 09:22:02 - push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "2023-09-11 09:22:02 - push_to_hub_organization=None,\n",
      "2023-09-11 09:22:02 - push_to_hub_model_id=None,\n",
      "2023-09-11 09:22:02 - sortish_sampler=False,\n",
      "2023-09-11 09:22:02 - skip_memory_metrics=True,\n",
      "2023-09-11 09:22:02 - sharded_ddp=[],\n",
      "2023-09-11 09:22:02 - seed=42,\n",
      "2023-09-11 09:22:02 - save_total_limit=None,\n",
      "2023-09-11 09:22:02 - save_strategy=steps,\n",
      "2023-09-11 09:22:02 - save_steps=50,\n",
      "2023-09-11 09:22:02 - use_legacy_prediction_loop=False,\n",
      "2023-09-11 09:22:02 - use_ipex=False,\n",
      "2023-09-11 09:22:02 - tpu_num_cores=None,\n",
      "2023-09-11 09:22:02 - tpu_metrics_debug=False,\n",
      "2023-09-11 09:22:02 - torchdynamo=None,\n",
      "2023-09-11 09:22:02 - torch_compile_mode=None,\n",
      "2023-09-11 09:22:02 - torch_compile_backend=None,\n",
      "2023-09-11 09:22:02 - torch_compile=False,\n",
      "2023-09-11 09:22:02 - tf32=None,\n",
      "2023-09-11 09:22:02 - 09/11/2023 09:22:02 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "2023-09-11 09:22:02 - )\n",
      "2023-09-11 09:22:02 - xpu_backend=None,\n",
      "2023-09-11 09:22:02 - weight_decay=0.0,\n",
      "2023-09-11 09:22:02 - warmup_steps=200,\n",
      "2023-09-11 09:22:02 - warmup_ratio=0.0,\n",
      "2023-09-11 09:22:02 - use_mps_device=False,\n",
      "2023-09-11 09:22:03 - Downloading and preparing dataset None/None (download: 120.09 MiB, generated: 121.04 MiB, post-processed: Unknown size, total: 241.14 MiB) to /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "2023-09-11 09:22:06 - Dataset parquet downloaded and prepared to /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "2023-09-11 09:22:06 - 09/11/2023 09:22:06 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-11 09:22:07 - 09/11/2023 09:22:07 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-11 09:22:07 - 09/11/2023 09:22:07 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-11 09:22:30 - \n",
      "2023-09-11 09:22:30 - [INFO|modeling_utils.py:3295] 2023-09-11 09:22:30,342 >> All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "2023-09-11 09:22:30 - If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "2023-09-11 09:22:30 - [INFO|modeling_utils.py:3303] 2023-09-11 09:22:30,342 >> All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at openai/whisper-medium.\n",
      "2023-09-11 09:22:30 - [INFO|configuration_utils.py:539] 2023-09-11 09:22:30,566 >> loading configuration file generation_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/18530d7c5ce1083f21426064b85fbd1e24bd1858/generation_config.json\n",
      "Downloading (…)neration_config.json: 100% 3.69k/3.69k [00:00<00:00, 1.91MB/s]\n",
      "2023-09-11 09:22:30 -       13,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -   \"alignment_heads\": [\n",
      "2023-09-11 09:22:30 - [INFO|configuration_utils.py:577] 2023-09-11 09:22:30,567 >> Generate config GenerationConfig {\n",
      "2023-09-11 09:22:30 -       4\n",
      "2023-09-11 09:22:30 -       15,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -       15\n",
      "2023-09-11 09:22:30 -       16,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -       15\n",
      "2023-09-11 09:22:30 -       15,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -       0\n",
      "2023-09-11 09:22:30 -       20,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -       1\n",
      "2023-09-11 09:22:30 -   ],\n",
      "2023-09-11 09:22:30 -     ]\n",
      "2023-09-11 09:22:30 -       4\n",
      "2023-09-11 09:22:30 -       23,\n",
      "2023-09-11 09:22:30 -   \"forced_decoder_ids\": [\n",
      "2023-09-11 09:22:30 -   \"eos_token_id\": 50257,\n",
      "2023-09-11 09:22:30 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-11 09:22:30 -   \"bos_token_id\": 50257,\n",
      "2023-09-11 09:22:30 -   ],\n",
      "2023-09-11 09:22:30 -     50257\n",
      "2023-09-11 09:22:30 -     220,\n",
      "2023-09-11 09:22:30 -   \"begin_suppress_tokens\": [\n",
      "2023-09-11 09:22:30 -       50359\n",
      "2023-09-11 09:22:30 -       2,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     ],\n",
      "2023-09-11 09:22:30 -       null\n",
      "2023-09-11 09:22:30 -       1,\n",
      "2023-09-11 09:22:30 -     [\n",
      "2023-09-11 09:22:30 -     \"<|as|>\": 50350,\n",
      "2023-09-11 09:22:30 -     \"<|ar|>\": 50272,\n",
      "2023-09-11 09:22:30 -     \"<|am|>\": 50334,\n",
      "2023-09-11 09:22:30 -     \"<|af|>\": 50327,\n",
      "2023-09-11 09:22:30 -   \"lang_to_id\": {\n",
      "2023-09-11 09:22:30 -   \"is_multilingual\": true,\n",
      "2023-09-11 09:22:30 -   ],\n",
      "2023-09-11 09:22:30 -     ]\n",
      "2023-09-11 09:22:30 -     \"<|br|>\": 50309,\n",
      "2023-09-11 09:22:30 -     \"<|bo|>\": 50347,\n",
      "2023-09-11 09:22:30 -     \"<|bn|>\": 50302,\n",
      "2023-09-11 09:22:30 -     \"<|bg|>\": 50292,\n",
      "2023-09-11 09:22:30 -     \"<|be|>\": 50330,\n",
      "2023-09-11 09:22:30 -     \"<|ba|>\": 50355,\n",
      "2023-09-11 09:22:30 -     \"<|az|>\": 50304,\n",
      "2023-09-11 09:22:30 -     \"<|da|>\": 50285,\n",
      "2023-09-11 09:22:30 -     \"<|cy|>\": 50297,\n",
      "2023-09-11 09:22:30 -     \"<|cs|>\": 50283,\n",
      "2023-09-11 09:22:30 -     \"<|ca|>\": 50270,\n",
      "2023-09-11 09:22:30 -     \"<|bs|>\": 50315,\n",
      "2023-09-11 09:22:30 -     \"<|fi|>\": 50277,\n",
      "2023-09-11 09:22:30 -     \"<|fa|>\": 50300,\n",
      "2023-09-11 09:22:30 -     \"<|eu|>\": 50310,\n",
      "2023-09-11 09:22:30 -     \"<|et|>\": 50307,\n",
      "2023-09-11 09:22:30 -     \"<|es|>\": 50262,\n",
      "2023-09-11 09:22:30 -     \"<|en|>\": 50259,\n",
      "2023-09-11 09:22:30 -     \"<|el|>\": 50281,\n",
      "2023-09-11 09:22:30 -     \"<|de|>\": 50261,\n",
      "2023-09-11 09:22:30 -     \"<|he|>\": 50279,\n",
      "2023-09-11 09:22:30 -     \"<|ha|>\": 50354,\n",
      "2023-09-11 09:22:30 -     \"<|haw|>\": 50352,\n",
      "2023-09-11 09:22:30 -     \"<|gu|>\": 50333,\n",
      "2023-09-11 09:22:30 -     \"<|gl|>\": 50319,\n",
      "2023-09-11 09:22:30 -     \"<|fr|>\": 50265,\n",
      "2023-09-11 09:22:30 -     \"<|fo|>\": 50338,\n",
      "2023-09-11 09:22:30 -     \"<|hy|>\": 50312,\n",
      "2023-09-11 09:22:30 -     \"<|hu|>\": 50286,\n",
      "2023-09-11 09:22:30 -     \"<|ht|>\": 50339,\n",
      "2023-09-11 09:22:30 -     \"<|hr|>\": 50291,\n",
      "2023-09-11 09:22:30 -     \"<|hi|>\": 50276,\n",
      "2023-09-11 09:22:30 -     \"<|ko|>\": 50264,\n",
      "2023-09-11 09:22:30 -     \"<|kn|>\": 50306,\n",
      "2023-09-11 09:22:30 -     \"<|km|>\": 50323,\n",
      "2023-09-11 09:22:30 -     \"<|kk|>\": 50316,\n",
      "2023-09-11 09:22:30 -     \"<|ka|>\": 50329,\n",
      "2023-09-11 09:22:30 -     \"<|jw|>\": 50356,\n",
      "2023-09-11 09:22:30 -     \"<|ja|>\": 50266,\n",
      "2023-09-11 09:22:30 -     \"<|it|>\": 50274,\n",
      "2023-09-11 09:22:30 -     \"<|is|>\": 50311,\n",
      "2023-09-11 09:22:30 -     \"<|id|>\": 50275,\n",
      "2023-09-11 09:22:30 -     \"<|lt|>\": 50293,\n",
      "2023-09-11 09:22:30 -     \"<|lo|>\": 50336,\n",
      "2023-09-11 09:22:30 -     \"<|ln|>\": 50353,\n",
      "2023-09-11 09:22:30 -     \"<|lb|>\": 50345,\n",
      "2023-09-11 09:22:30 -     \"<|la|>\": 50294,\n",
      "2023-09-11 09:22:30 -     \"<|mr|>\": 50320,\n",
      "2023-09-11 09:22:30 -     \"<|mn|>\": 50314,\n",
      "2023-09-11 09:22:30 -     \"<|ml|>\": 50296,\n",
      "2023-09-11 09:22:30 -     \"<|mk|>\": 50308,\n",
      "2023-09-11 09:22:30 -     \"<|mi|>\": 50295,\n",
      "2023-09-11 09:22:30 -     \"<|mg|>\": 50349,\n",
      "2023-09-11 09:22:30 -     \"<|lv|>\": 50301,\n",
      "2023-09-11 09:22:30 -     \"<|oc|>\": 50328,\n",
      "2023-09-11 09:22:30 -     \"<|no|>\": 50288,\n",
      "2023-09-11 09:22:30 -     \"<|nn|>\": 50342,\n",
      "2023-09-11 09:22:30 -     \"<|nl|>\": 50271,\n",
      "2023-09-11 09:22:30 -     \"<|ne|>\": 50313,\n",
      "2023-09-11 09:22:30 -     \"<|my|>\": 50346,\n",
      "2023-09-11 09:22:30 -     \"<|mt|>\": 50343,\n",
      "2023-09-11 09:22:30 -     \"<|ms|>\": 50282,\n",
      "2023-09-11 09:22:30 -     \"<|sa|>\": 50344,\n",
      "2023-09-11 09:22:30 -     \"<|ru|>\": 50263,\n",
      "2023-09-11 09:22:30 -     \"<|ro|>\": 50284,\n",
      "2023-09-11 09:22:30 -     \"<|pt|>\": 50267,\n",
      "2023-09-11 09:22:30 -     \"<|ps|>\": 50340,\n",
      "2023-09-11 09:22:30 -     \"<|pl|>\": 50269,\n",
      "2023-09-11 09:22:30 -     \"<|pa|>\": 50321,\n",
      "2023-09-11 09:22:30 -     \"<|sr|>\": 50303,\n",
      "2023-09-11 09:22:30 -     \"<|sq|>\": 50317,\n",
      "2023-09-11 09:22:30 -     \"<|so|>\": 50326,\n",
      "2023-09-11 09:22:30 -     \"<|sn|>\": 50324,\n",
      "2023-09-11 09:22:30 -     \"<|sl|>\": 50305,\n",
      "2023-09-11 09:22:30 -     \"<|sk|>\": 50298,\n",
      "2023-09-11 09:22:30 -     \"<|si|>\": 50322,\n",
      "2023-09-11 09:22:30 -     \"<|sd|>\": 50332,\n",
      "2023-09-11 09:22:30 -     \"<|th|>\": 50289,\n",
      "2023-09-11 09:22:30 -     \"<|tg|>\": 50331,\n",
      "2023-09-11 09:22:30 -     \"<|te|>\": 50299,\n",
      "2023-09-11 09:22:30 -     \"<|ta|>\": 50287,\n",
      "2023-09-11 09:22:30 -     \"<|sw|>\": 50318,\n",
      "2023-09-11 09:22:30 -     \"<|sv|>\": 50273,\n",
      "2023-09-11 09:22:30 -     \"<|su|>\": 50357,\n",
      "2023-09-11 09:22:30 -     \"<|uk|>\": 50280,\n",
      "2023-09-11 09:22:30 -     \"<|tt|>\": 50351,\n",
      "2023-09-11 09:22:30 -     \"<|tr|>\": 50268,\n",
      "2023-09-11 09:22:30 -     \"<|tl|>\": 50348,\n",
      "2023-09-11 09:22:30 -     \"<|tk|>\": 50341,\n",
      "2023-09-11 09:22:30 -   \"max_initial_timestamp_index\": 1,\n",
      "2023-09-11 09:22:30 -   },\n",
      "2023-09-11 09:22:30 -     \"<|zh|>\": 50260\n",
      "2023-09-11 09:22:30 -     \"<|yo|>\": 50325,\n",
      "2023-09-11 09:22:30 -     \"<|yi|>\": 50335,\n",
      "2023-09-11 09:22:30 -     \"<|vi|>\": 50278,\n",
      "2023-09-11 09:22:30 -     \"<|uz|>\": 50337,\n",
      "2023-09-11 09:22:30 -     \"<|ur|>\": 50290,\n",
      "2023-09-11 09:22:30 -     7,\n",
      "2023-09-11 09:22:30 -     2,\n",
      "2023-09-11 09:22:30 -     1,\n",
      "2023-09-11 09:22:30 -   \"suppress_tokens\": [\n",
      "2023-09-11 09:22:30 -   \"pad_token_id\": 50257,\n",
      "2023-09-11 09:22:30 -   \"no_timestamps_token_id\": 50363,\n",
      "2023-09-11 09:22:30 -   \"max_length\": 448,\n",
      "2023-09-11 09:22:30 -     28,\n",
      "2023-09-11 09:22:30 -     27,\n",
      "2023-09-11 09:22:30 -     26,\n",
      "2023-09-11 09:22:30 -     25,\n",
      "2023-09-11 09:22:30 -     14,\n",
      "2023-09-11 09:22:30 -     10,\n",
      "2023-09-11 09:22:30 -     9,\n",
      "2023-09-11 09:22:30 -     8,\n",
      "2023-09-11 09:22:30 -     62,\n",
      "2023-09-11 09:22:30 -     61,\n",
      "2023-09-11 09:22:30 -     60,\n",
      "2023-09-11 09:22:30 -     59,\n",
      "2023-09-11 09:22:30 -     58,\n",
      "2023-09-11 09:22:30 -     31,\n",
      "2023-09-11 09:22:30 -     29,\n",
      "2023-09-11 09:22:30 -     522,\n",
      "2023-09-11 09:22:30 -     503,\n",
      "2023-09-11 09:22:30 -     359,\n",
      "2023-09-11 09:22:30 -     93,\n",
      "2023-09-11 09:22:30 -     92,\n",
      "2023-09-11 09:22:30 -     91,\n",
      "2023-09-11 09:22:30 -     90,\n",
      "2023-09-11 09:22:30 -     63,\n",
      "2023-09-11 09:22:30 -     918,\n",
      "2023-09-11 09:22:30 -     902,\n",
      "2023-09-11 09:22:30 -     893,\n",
      "2023-09-11 09:22:30 -     873,\n",
      "2023-09-11 09:22:30 -     542,\n",
      "2023-09-11 09:22:30 -     2627,\n",
      "2023-09-11 09:22:30 -     2460,\n",
      "2023-09-11 09:22:30 -     1982,\n",
      "2023-09-11 09:22:30 -     1853,\n",
      "2023-09-11 09:22:30 -     1350,\n",
      "2023-09-11 09:22:30 -     931,\n",
      "2023-09-11 09:22:30 -     922,\n",
      "2023-09-11 09:22:30 -     4183,\n",
      "2023-09-11 09:22:30 -     3961,\n",
      "2023-09-11 09:22:30 -     3846,\n",
      "2023-09-11 09:22:30 -     3536,\n",
      "2023-09-11 09:22:30 -     3268,\n",
      "2023-09-11 09:22:30 -     3253,\n",
      "2023-09-11 09:22:30 -     3246,\n",
      "2023-09-11 09:22:30 -     10929,\n",
      "2023-09-11 09:22:30 -     10428,\n",
      "2023-09-11 09:22:30 -     9383,\n",
      "2023-09-11 09:22:30 -     9061,\n",
      "2023-09-11 09:22:30 -     7273,\n",
      "2023-09-11 09:22:30 -     6647,\n",
      "2023-09-11 09:22:30 -     6585,\n",
      "2023-09-11 09:22:30 -     4667,\n",
      "2023-09-11 09:22:30 -     47425,\n",
      "2023-09-11 09:22:30 -     42863,\n",
      "2023-09-11 09:22:30 -     36865,\n",
      "2023-09-11 09:22:30 -     32470,\n",
      "2023-09-11 09:22:30 -     32302,\n",
      "2023-09-11 09:22:30 -     31650,\n",
      "2023-09-11 09:22:30 -     29464,\n",
      "2023-09-11 09:22:30 -     28279,\n",
      "2023-09-11 09:22:30 -     26435,\n",
      "2023-09-11 09:22:30 -     26161,\n",
      "2023-09-11 09:22:30 -     26130,\n",
      "2023-09-11 09:22:30 -     22520,\n",
      "2023-09-11 09:22:30 -     21675,\n",
      "2023-09-11 09:22:30 -     20075,\n",
      "2023-09-11 09:22:30 -     18956,\n",
      "2023-09-11 09:22:30 -     18362,\n",
      "2023-09-11 09:22:30 -     16604,\n",
      "2023-09-11 09:22:30 -     16553,\n",
      "2023-09-11 09:22:30 -     15618,\n",
      "2023-09-11 09:22:30 -     15265,\n",
      "2023-09-11 09:22:30 -     14635,\n",
      "2023-09-11 09:22:30 -     14157,\n",
      "2023-09-11 09:22:30 -     13793,\n",
      "2023-09-11 09:22:30 -     12562,\n",
      "2023-09-11 09:22:30 -     12331,\n",
      "2023-09-11 09:22:30 -     12033,\n",
      "2023-09-11 09:22:30 -     11938,\n",
      "2023-09-11 09:22:30 -     50258,\n",
      "2023-09-11 09:22:30 -     50254,\n",
      "2023-09-11 09:22:30 -     49870,\n",
      "2023-09-11 09:22:30 -   \"task_to_id\": {\n",
      "2023-09-11 09:22:30 -   ],\n",
      "2023-09-11 09:22:30 -     50362\n",
      "2023-09-11 09:22:30 -     50361,\n",
      "2023-09-11 09:22:30 -     50360,\n",
      "2023-09-11 09:22:30 -     50359,\n",
      "2023-09-11 09:22:30 -     50358,\n",
      "2023-09-11 09:22:30 - \n",
      "2023-09-11 09:22:30 - }\n",
      "2023-09-11 09:22:30 -   \"transformers_version\": \"4.30.2\"\n",
      "2023-09-11 09:22:30 -   },\n",
      "2023-09-11 09:22:30 -     \"translate\": 50358\n",
      "2023-09-11 09:22:30 -     \"transcribe\": 50359,\n",
      "Downloading builder script: 100% 4.49k/4.49k [00:00<00:00, 7.58MB/s]  \n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:2194] 2023-09-11 09:22:54,594 >> tokenizer config file saved in /mnt/output/tokenizer_config.json\n",
      "2023-09-11 09:22:54 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:22:54,594 >> Feature extractor saved in /mnt/output/preprocessor_config.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:2201] 2023-09-11 09:22:54,594 >> Special tokens file saved in /mnt/output/special_tokens_map.json\n",
      "2023-09-11 09:22:54 - [INFO|configuration_utils.py:458] 2023-09-11 09:22:54,701 >> Configuration saved in /mnt/output/config.json\n",
      "Downloading builder script: 100% 4.49k/4.49k [00:00<00:00, 5.10MB/s]\n",
      "2023-09-11 09:22:54 - [INFO|image_processing_utils.py:307] 2023-09-11 09:22:54,748 >> loading configuration file /mnt/output/preprocessor_config.json\n",
      "2023-09-11 09:22:54 - [INFO|feature_extraction_utils.py:519] 2023-09-11 09:22:54,755 >> Feature extractor WhisperFeatureExtractor {\n",
      "2023-09-11 09:22:54 - [INFO|feature_extraction_utils.py:475] 2023-09-11 09:22:54,755 >> loading configuration file /mnt/output/preprocessor_config.json\n",
      "2023-09-11 09:22:54 -   \"n_fft\": 400,\n",
      "2023-09-11 09:22:54 -   \"hop_length\": 160,\n",
      "2023-09-11 09:22:54 -   \"feature_size\": 80,\n",
      "2023-09-11 09:22:54 -   \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "2023-09-11 09:22:54 -   \"chunk_length\": 30,\n",
      "2023-09-11 09:22:54 -   \"processor_class\": \"WhisperProcessor\",\n",
      "2023-09-11 09:22:54 -   \"padding_value\": 0.0,\n",
      "2023-09-11 09:22:54 -   \"padding_side\": \"right\",\n",
      "2023-09-11 09:22:54 -   \"nb_max_frames\": 3000,\n",
      "2023-09-11 09:22:54 -   \"n_samples\": 480000,\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,756 >> loading file merges.txt\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,755 >> loading file tokenizer.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,755 >> loading file vocab.json\n",
      "2023-09-11 09:22:54 - \n",
      "2023-09-11 09:22:54 - }\n",
      "2023-09-11 09:22:54 -   \"sampling_rate\": 16000\n",
      "2023-09-11 09:22:54 -   \"return_attention_mask\": false,\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,756 >> loading file tokenizer_config.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,756 >> loading file special_tokens_map.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,756 >> loading file added_tokens.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils_base.py:1821] 2023-09-11 09:22:54,756 >> loading file normalizer.json\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|de|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|zh|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|en|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|startoftranscript|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|pl|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|tr|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|pt|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|ja|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|fr|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|ko|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|ru|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,813 >> Adding <|es|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|nl|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ca|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|id|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|it|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|sv|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ar|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ms|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|el|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|uk|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|he|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|vi|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|fi|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|hi|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ur|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|th|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|no|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ta|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|hu|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|da|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ro|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|cs|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|cy|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|ml|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|mi|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|la|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|lt|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|bg|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|hr|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|sl|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|az|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|sr|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|bn|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|lv|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|fa|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|te|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,814 >> Adding <|sk|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|eu|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|br|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|mk|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|et|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|kn|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|sq|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|kk|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|bs|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|mn|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|ne|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|hy|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|is|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|yo|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|sn|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|km|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|si|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|pa|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|mr|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|gl|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|sw|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|ka|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|oc|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|af|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|so|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|lo|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|yi|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|am|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|gu|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|sd|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|tg|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|be|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|sa|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|mt|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|nn|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|tk|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|ps|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|ht|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|fo|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,815 >> Adding <|uz|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|tt|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|as|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|mg|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|tl|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|bo|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|my|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|lb|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|transcribe|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|translate|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|su|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|jw|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|ba|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|ha|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|ln|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|haw|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|notimestamps|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|nocaptions|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|startofprev|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,816 >> Adding <|startoflm|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,820 >> Adding <|0.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,821 >> Adding <|0.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,822 >> Adding <|1.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|1.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,823 >> Adding <|2.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|3.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,824 >> Adding <|2.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,825 >> Adding <|3.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|3.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,826 >> Adding <|4.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|5.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|5.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|5.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|5.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,827 >> Adding <|4.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,828 >> Adding <|5.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|5.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,829 >> Adding <|6.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|6.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,830 >> Adding <|6.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|6.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|6.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|6.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|6.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,831 >> Adding <|7.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.94|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.84|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.06|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.04|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|8.02|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|8.00|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.98|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,832 >> Adding <|7.96|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.18|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.16|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.14|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.12|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.10|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.08|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.30|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.28|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.26|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.24|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.22|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.20|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.42|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.40|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.38|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.36|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.34|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.32|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.60|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.58|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.56|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.54|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.52|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.50|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.48|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.46|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,833 >> Adding <|8.44|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.72|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.70|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.68|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.66|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.64|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.62|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.82|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.80|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.78|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.76|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.74|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.92|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.90|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.88|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.86|> to the vocabulary\n",
      "2023-09-11 09:22:54 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|9.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,834 >> Adding <|8.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,835 >> Adding <|9.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|9.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,836 >> Adding <|10.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,837 >> Adding <|10.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|10.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,838 >> Adding <|11.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|11.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|11.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,839 >> Adding <|11.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|11.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|11.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|11.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,840 >> Adding <|12.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|12.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,841 >> Adding <|12.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,842 >> Adding <|13.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|14.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,843 >> Adding <|13.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,844 >> Adding <|14.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|15.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|15.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,845 >> Adding <|14.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,846 >> Adding <|15.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|16.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|16.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,847 >> Adding <|15.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,848 >> Adding <|16.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,849 >> Adding <|16.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,850 >> Adding <|17.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|17.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|17.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|17.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|17.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,851 >> Adding <|17.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,852 >> Adding <|18.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,853 >> Adding <|18.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|18.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,854 >> Adding <|19.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,855 >> Adding <|19.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|19.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,856 >> Adding <|20.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,857 >> Adding <|20.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|21.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|21.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|21.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,858 >> Adding <|20.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,859 >> Adding <|21.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|21.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,860 >> Adding <|21.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|21.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|21.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|21.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,861 >> Adding <|22.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,862 >> Adding <|22.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|22.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,863 >> Adding <|23.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,864 >> Adding <|23.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,865 >> Adding <|23.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|23.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|23.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,866 >> Adding <|24.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,867 >> Adding <|24.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|24.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,868 >> Adding <|25.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,869 >> Adding <|25.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|25.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|25.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|25.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|25.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,870 >> Adding <|25.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|25.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,871 >> Adding <|26.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,872 >> Adding <|26.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|27.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,873 >> Adding <|26.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,874 >> Adding <|27.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,875 >> Adding <|27.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|28.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|28.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|28.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|28.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|28.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,876 >> Adding <|27.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,877 >> Adding <|28.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,878 >> Adding <|28.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.06|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.04|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.02|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|28.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.20|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.18|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.16|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.14|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.12|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.10|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,879 >> Adding <|29.08|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.30|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.28|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.26|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.24|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.22|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.40|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.38|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.36|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.34|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.32|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.60|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.58|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.56|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.54|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.52|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.50|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.48|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.46|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.44|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,880 >> Adding <|29.42|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.68|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.66|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.64|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.62|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.82|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.80|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.78|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.76|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.74|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.72|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.70|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.96|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.94|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.92|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.90|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.88|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.86|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,881 >> Adding <|29.84|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:577] 2023-09-11 09:22:55,257 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|30.00|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|tokenization_utils.py:426] 2023-09-11 09:22:54,882 >> Adding <|29.98|> to the vocabulary\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1793] 2023-09-11 09:22:55,494 >>   Number of trainable parameters = 763,857,920\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1792] 2023-09-11 09:22:55,491 >>   Total optimization steps = 1,000\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1791] 2023-09-11 09:22:55,491 >>   Gradient Accumulation steps = 8\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1790] 2023-09-11 09:22:55,491 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1789] 2023-09-11 09:22:55,491 >>   Instantaneous batch size per device = 2\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1788] 2023-09-11 09:22:55,491 >>   Num Epochs = 67\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1787] 2023-09-11 09:22:55,491 >>   Num examples = 504\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:1786] 2023-09-11 09:22:55,491 >> ***** Running training *****\n",
      "2023-09-11 09:22:55 - [INFO|trainer.py:776] 2023-09-11 09:22:55,413 >> The following columns in the training set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:25:50 - {'loss': 2.5616, 'learning_rate': 1.2000000000000002e-06, 'epoch': 1.59}\n",
      "2023-09-11 09:28:44 - {'loss': 1.3051, 'learning_rate': 2.4000000000000003e-06, 'epoch': 3.17}\n",
      " 75% 3/4 [00:15<00:05,  5.33s/it]\u001b[A\n",
      "  5% 50/1000 [06:19<1:50:39,  6.99s/it]\n",
      "                                       \n",
      "100% 4/4 [00:22<00:00,  6.14s/it]\u001b[A\n",
      "2023-09-11 09:29:15 - [INFO|configuration_utils.py:458] 2023-09-11 09:29:15,287 >> Configuration saved in /mnt/output/checkpoint-50/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 09:29:15,286 >> Saving model checkpoint to /mnt/output/checkpoint-50\n",
      "2023-09-11 09:29:15 - [INFO|configuration_utils.py:364] 2023-09-11 09:29:15,288 >> Configuration saved in /mnt/output/checkpoint-50/generation_config.json\n",
      "2023-09-11 09:29:17 - [INFO|modeling_utils.py:1853] 2023-09-11 09:29:17,974 >> Model weights saved in /mnt/output/checkpoint-50/pytorch_model.bin\n",
      "2023-09-11 09:29:17 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:29:17,976 >> Feature extractor saved in /mnt/output/checkpoint-50/preprocessor_config.json\n",
      "  5% 50/1000 [05:48<1:50:39,  6.99s/it][INFO|trainer.py:776] 2023-09-11 09:28:44,180 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:28:44 - [INFO|trainer.py:3205] 2023-09-11 09:28:44,182 >>   Batch size = 8\n",
      "2023-09-11 09:28:44 - [INFO|trainer.py:3202] 2023-09-11 09:28:44,182 >>   Num examples = 55\n",
      "2023-09-11 09:28:44 - [INFO|trainer.py:3200] 2023-09-11 09:28:44,181 >> ***** Running Evaluation *****\n",
      "2023-09-11 09:28:52 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:07<00:07,  3.74s/it]\u001b[A\n",
      "2023-09-11 09:29:15 - {'eval_loss': 0.9045917391777039, 'eval_wer': 0.5461465271170314, 'eval_runtime': 31.1011, 'eval_samples_per_second': 1.768, 'eval_steps_per_second': 0.129, 'epoch': 3.17}\n",
      "2023-09-11 09:32:18 - {'loss': 0.5214, 'learning_rate': 3.65e-06, 'epoch': 4.76}\n",
      "2023-09-11 09:35:13 - {'loss': 0.2137, 'learning_rate': 4.9000000000000005e-06, 'epoch': 6.35}\n",
      "2023-09-11 09:35:42 - {'eval_loss': 0.5140445232391357, 'eval_wer': 0.28068506184586106, 'eval_runtime': 29.5692, 'eval_samples_per_second': 1.86, 'eval_steps_per_second': 0.135, 'epoch': 6.35}\n",
      " 10% 100/1000 [12:17<1:45:01,  7.00s/it][INFO|trainer.py:776] 2023-09-11 09:35:13,263 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:35:13 - [INFO|trainer.py:3205] 2023-09-11 09:35:13,265 >>   Batch size = 8\n",
      "2023-09-11 09:35:13 - [INFO|trainer.py:3202] 2023-09-11 09:35:13,265 >>   Num examples = 55\n",
      "2023-09-11 09:35:13 - [INFO|trainer.py:3200] 2023-09-11 09:35:13,264 >> ***** Running Evaluation *****\n",
      "2023-09-11 09:35:20 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:07<00:07,  3.70s/it]\u001b[A\n",
      " 75% 3/4 [00:14<00:05,  5.23s/it]\u001b[A\n",
      "100% 4/4 [00:22<00:00,  6.03s/it]\u001b[A\n",
      " 10% 100/1000 [12:47<1:45:01,  7.00s/it]\n",
      "                                        \n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 09:35:42,884 >> Saving model checkpoint to /mnt/output/checkpoint-100\n",
      "2023-09-11 09:35:42 - [INFO|configuration_utils.py:364] 2023-09-11 09:35:42,886 >> Configuration saved in /mnt/output/checkpoint-100/generation_config.json\n",
      "2023-09-11 09:35:42 - [INFO|configuration_utils.py:458] 2023-09-11 09:35:42,885 >> Configuration saved in /mnt/output/checkpoint-100/config.json\n",
      "2023-09-11 09:35:45 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:35:45,523 >> Feature extractor saved in /mnt/output/checkpoint-100/preprocessor_config.json\n",
      "2023-09-11 09:35:45 - [INFO|modeling_utils.py:1853] 2023-09-11 09:35:45,522 >> Model weights saved in /mnt/output/checkpoint-100/pytorch_model.bin\n",
      "2023-09-11 09:38:45 - {'loss': 0.0798, 'learning_rate': 6.15e-06, 'epoch': 7.94}\n",
      "2023-09-11 09:41:39 - {'loss': 0.0343, 'learning_rate': 7.4e-06, 'epoch': 9.52}\n",
      "2023-09-11 09:41:57 - {'eval_loss': 0.5870081782341003, 'eval_wer': 0.1665080875356803, 'eval_runtime': 17.8913, 'eval_samples_per_second': 3.074, 'eval_steps_per_second': 0.224, 'epoch': 9.52}\n",
      " 15% 150/1000 [18:43<1:38:48,  6.97s/it][INFO|trainer.py:776] 2023-09-11 09:41:39,569 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:41:39 - [INFO|trainer.py:3205] 2023-09-11 09:41:39,570 >>   Batch size = 8\n",
      "2023-09-11 09:41:39 - [INFO|trainer.py:3202] 2023-09-11 09:41:39,570 >>   Num examples = 55\n",
      "2023-09-11 09:41:39 - [INFO|trainer.py:3200] 2023-09-11 09:41:39,570 >> ***** Running Evaluation *****\n",
      "2023-09-11 09:41:43 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.11s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.31s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.68s/it]\u001b[A\n",
      " 15% 150/1000 [19:01<1:38:48,  6.97s/it]\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 09:41:57,512 >> Saving model checkpoint to /mnt/output/checkpoint-150\n",
      "2023-09-11 09:41:57 - [INFO|configuration_utils.py:458] 2023-09-11 09:41:57,513 >> Configuration saved in /mnt/output/checkpoint-150/config.json\n",
      "2023-09-11 09:41:57 - [INFO|configuration_utils.py:364] 2023-09-11 09:41:57,514 >> Configuration saved in /mnt/output/checkpoint-150/generation_config.json\n",
      "2023-09-11 09:42:00 - [INFO|modeling_utils.py:1853] 2023-09-11 09:42:00,151 >> Model weights saved in /mnt/output/checkpoint-150/pytorch_model.bin\n",
      "2023-09-11 09:42:00 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:42:00,153 >> Feature extractor saved in /mnt/output/checkpoint-150/preprocessor_config.json\n",
      "2023-09-11 09:44:59 - {'loss': 0.0236, 'learning_rate': 8.65e-06, 'epoch': 11.11}\n",
      "2023-09-11 09:47:53 - {'loss': 0.0171, 'learning_rate': 9.9e-06, 'epoch': 12.7}\n",
      "2023-09-11 09:48:11 - {'eval_loss': 0.5955320000648499, 'eval_wer': 0.1665080875356803, 'eval_runtime': 17.9943, 'eval_samples_per_second': 3.057, 'eval_steps_per_second': 0.222, 'epoch': 12.7}\n",
      " 20% 200/1000 [24:57<1:32:47,  6.96s/it][INFO|trainer.py:776] 2023-09-11 09:47:53,613 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:47:53 - [INFO|trainer.py:3205] 2023-09-11 09:47:53,614 >>   Batch size = 8\n",
      "2023-09-11 09:47:53 - [INFO|trainer.py:3202] 2023-09-11 09:47:53,614 >>   Num examples = 55\n",
      "2023-09-11 09:47:53 - [INFO|trainer.py:3200] 2023-09-11 09:47:53,614 >> ***** Running Evaluation *****\n",
      "2023-09-11 09:47:57 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.10s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.32s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.70s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 09:48:11,611 >> Saving model checkpoint to /mnt/output/checkpoint-200\n",
      " 20% 200/1000 [25:15<1:32:47,  6.96s/it]\n",
      "                                        \n",
      "2023-09-11 09:48:11 - [INFO|configuration_utils.py:364] 2023-09-11 09:48:11,613 >> Configuration saved in /mnt/output/checkpoint-200/generation_config.json\n",
      "2023-09-11 09:48:11 - [INFO|configuration_utils.py:458] 2023-09-11 09:48:11,612 >> Configuration saved in /mnt/output/checkpoint-200/config.json\n",
      "2023-09-11 09:48:14 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:48:14,240 >> Feature extractor saved in /mnt/output/checkpoint-200/preprocessor_config.json\n",
      "2023-09-11 09:48:14 - [INFO|modeling_utils.py:1853] 2023-09-11 09:48:14,239 >> Model weights saved in /mnt/output/checkpoint-200/pytorch_model.bin\n",
      "2023-09-11 09:51:13 - {'loss': 0.0115, 'learning_rate': 9.7125e-06, 'epoch': 14.29}\n",
      " 25% 250/1000 [31:12<1:27:03,  6.96s/it][INFO|trainer.py:776] 2023-09-11 09:54:07,783 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 09:54:07 - [INFO|trainer.py:3205] 2023-09-11 09:54:07,785 >>   Batch size = 8\n",
      "2023-09-11 09:54:07 - [INFO|trainer.py:3202] 2023-09-11 09:54:07,785 >>   Num examples = 55\n",
      "2023-09-11 09:54:07 - [INFO|trainer.py:3200] 2023-09-11 09:54:07,784 >> ***** Running Evaluation *****\n",
      "2023-09-11 09:54:12 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.09s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.28s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.69s/it]\u001b[A\n",
      " 25% 250/1000 [31:30<1:27:03,  6.96s/it]\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 09:54:25,767 >> Saving model checkpoint to /mnt/output/checkpoint-250\n",
      "2023-09-11 09:54:25 - [INFO|configuration_utils.py:458] 2023-09-11 09:54:25,768 >> Configuration saved in /mnt/output/checkpoint-250/config.json\n",
      "2023-09-11 09:54:25 - [INFO|configuration_utils.py:364] 2023-09-11 09:54:25,769 >> Configuration saved in /mnt/output/checkpoint-250/generation_config.json\n",
      "2023-09-11 09:54:28 - [INFO|feature_extraction_utils.py:377] 2023-09-11 09:54:28,421 >> Feature extractor saved in /mnt/output/checkpoint-250/preprocessor_config.json\n",
      "2023-09-11 09:54:28 - [INFO|modeling_utils.py:1853] 2023-09-11 09:54:28,420 >> Model weights saved in /mnt/output/checkpoint-250/pytorch_model.bin\n",
      "2023-09-11 09:54:07 - {'loss': 0.0107, 'learning_rate': 9.4e-06, 'epoch': 15.87}\n",
      "2023-09-11 09:54:25 - {'eval_loss': 0.5995476245880127, 'eval_wer': 0.15413891531874405, 'eval_runtime': 17.9315, 'eval_samples_per_second': 3.067, 'eval_steps_per_second': 0.223, 'epoch': 15.87}\n",
      "2023-09-11 09:57:27 - {'loss': 0.006, 'learning_rate': 9.0875e-06, 'epoch': 17.46}\n",
      "2023-09-11 10:00:21 - {'loss': 0.0045, 'learning_rate': 8.775e-06, 'epoch': 19.05}\n",
      "2023-09-11 10:00:39 - {'eval_loss': 0.6287272572517395, 'eval_wer': 0.1731684110371075, 'eval_runtime': 17.73, 'eval_samples_per_second': 3.102, 'eval_steps_per_second': 0.226, 'epoch': 19.05}\n",
      " 30% 300/1000 [37:25<1:21:18,  6.97s/it][INFO|trainer.py:776] 2023-09-11 10:00:21,505 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:00:21 - [INFO|trainer.py:3205] 2023-09-11 10:00:21,506 >>   Batch size = 8\n",
      "2023-09-11 10:00:21 - [INFO|trainer.py:3202] 2023-09-11 10:00:21,506 >>   Num examples = 55\n",
      "2023-09-11 10:00:21 - [INFO|trainer.py:3200] 2023-09-11 10:00:21,506 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:00:25 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.27s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.64s/it]\u001b[A\n",
      " 30% 300/1000 [37:43<1:21:18,  6.97s/it]\n",
      "2023-09-11 10:00:39 - [INFO|configuration_utils.py:458] 2023-09-11 10:00:39,240 >> Configuration saved in /mnt/output/checkpoint-300/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:00:39,239 >> Saving model checkpoint to /mnt/output/checkpoint-300\n",
      "2023-09-11 10:00:39 - [INFO|configuration_utils.py:364] 2023-09-11 10:00:39,240 >> Configuration saved in /mnt/output/checkpoint-300/generation_config.json\n",
      "2023-09-11 10:00:41 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:00:41,869 >> Feature extractor saved in /mnt/output/checkpoint-300/preprocessor_config.json\n",
      "2023-09-11 10:00:41 - [INFO|modeling_utils.py:1853] 2023-09-11 10:00:41,868 >> Model weights saved in /mnt/output/checkpoint-300/pytorch_model.bin\n",
      "2023-09-11 10:03:41 - {'loss': 0.0037, 'learning_rate': 8.4625e-06, 'epoch': 20.63}\n",
      " 35% 350/1000 [43:39<1:15:30,  6.97s/it][INFO|trainer.py:776] 2023-09-11 10:06:34,815 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:06:34 - [INFO|trainer.py:3205] 2023-09-11 10:06:34,816 >>   Batch size = 8\n",
      "2023-09-11 10:06:34 - [INFO|trainer.py:3202] 2023-09-11 10:06:34,816 >>   Num examples = 55\n",
      "2023-09-11 10:06:34 - [INFO|trainer.py:3200] 2023-09-11 10:06:34,816 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:06:39 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.34s/it]\u001b[A\n",
      " 35% 350/1000 [43:57<1:15:30,  6.97s/it]\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.71s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:06:52,817 >> Saving model checkpoint to /mnt/output/checkpoint-350\n",
      "2023-09-11 10:06:52 - [INFO|configuration_utils.py:458] 2023-09-11 10:06:52,818 >> Configuration saved in /mnt/output/checkpoint-350/config.json\n",
      "2023-09-11 10:06:52 - [INFO|configuration_utils.py:364] 2023-09-11 10:06:52,818 >> Configuration saved in /mnt/output/checkpoint-350/generation_config.json\n",
      "2023-09-11 10:06:55 - [INFO|modeling_utils.py:1853] 2023-09-11 10:06:55,450 >> Model weights saved in /mnt/output/checkpoint-350/pytorch_model.bin\n",
      "2023-09-11 10:06:55 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:06:55,452 >> Feature extractor saved in /mnt/output/checkpoint-350/preprocessor_config.json\n",
      "2023-09-11 10:06:34 - {'loss': 0.0036, 'learning_rate': 8.15e-06, 'epoch': 22.22}\n",
      "2023-09-11 10:06:52 - {'eval_loss': 0.6432343125343323, 'eval_wer': 0.16555661274976213, 'eval_runtime': 17.9491, 'eval_samples_per_second': 3.064, 'eval_steps_per_second': 0.223, 'epoch': 22.22}\n",
      "2023-09-11 10:09:54 - {'loss': 0.0015, 'learning_rate': 7.8375e-06, 'epoch': 23.81}\n",
      " 40% 400/1000 [49:51<1:09:19,  6.93s/it][INFO|trainer.py:776] 2023-09-11 10:12:47,449 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:12:47 - [INFO|trainer.py:3205] 2023-09-11 10:12:47,450 >>   Batch size = 8\n",
      "2023-09-11 10:12:47 - [INFO|trainer.py:3202] 2023-09-11 10:12:47,450 >>   Num examples = 55\n",
      "2023-09-11 10:12:47 - [INFO|trainer.py:3200] 2023-09-11 10:12:47,450 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:12:51 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.08s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.28s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.67s/it]\u001b[A\n",
      " 40% 400/1000 [50:09<1:09:19,  6.93s/it]\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:13:05,298 >> Saving model checkpoint to /mnt/output/checkpoint-400\n",
      "2023-09-11 10:13:05 - [INFO|configuration_utils.py:458] 2023-09-11 10:13:05,299 >> Configuration saved in /mnt/output/checkpoint-400/config.json\n",
      "2023-09-11 10:13:05 - [INFO|configuration_utils.py:364] 2023-09-11 10:13:05,300 >> Configuration saved in /mnt/output/checkpoint-400/generation_config.json\n",
      "2023-09-11 10:13:07 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:13:07,946 >> Feature extractor saved in /mnt/output/checkpoint-400/preprocessor_config.json\n",
      "2023-09-11 10:13:07 - [INFO|modeling_utils.py:1853] 2023-09-11 10:13:07,945 >> Model weights saved in /mnt/output/checkpoint-400/pytorch_model.bin\n",
      "2023-09-11 10:12:47 - {'loss': 0.001, 'learning_rate': 7.525e-06, 'epoch': 25.4}\n",
      "2023-09-11 10:13:05 - {'eval_loss': 0.6878654956817627, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.7973, 'eval_samples_per_second': 3.09, 'eval_steps_per_second': 0.225, 'epoch': 25.4}\n",
      "2023-09-11 10:16:06 - {'loss': 0.0005, 'learning_rate': 7.2125e-06, 'epoch': 26.98}\n",
      " 45% 450/1000 [56:05<1:03:37,  6.94s/it][INFO|trainer.py:776] 2023-09-11 10:19:00,730 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:19:00 - [INFO|trainer.py:3205] 2023-09-11 10:19:00,731 >>   Batch size = 8\n",
      "2023-09-11 10:19:00 - [INFO|trainer.py:3202] 2023-09-11 10:19:00,731 >>   Num examples = 55\n",
      "2023-09-11 10:19:00 - [INFO|trainer.py:3200] 2023-09-11 10:19:00,731 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:19:05 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.08s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.28s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.69s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:19:18,737 >> Saving model checkpoint to /mnt/output/checkpoint-450\n",
      " 45% 450/1000 [56:23<1:03:37,  6.94s/it]\n",
      "2023-09-11 10:19:18 - [INFO|configuration_utils.py:364] 2023-09-11 10:19:18,739 >> Configuration saved in /mnt/output/checkpoint-450/generation_config.json\n",
      "2023-09-11 10:19:18 - [INFO|configuration_utils.py:458] 2023-09-11 10:19:18,738 >> Configuration saved in /mnt/output/checkpoint-450/config.json\n",
      "2023-09-11 10:19:21 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:19:21,426 >> Feature extractor saved in /mnt/output/checkpoint-450/preprocessor_config.json\n",
      "2023-09-11 10:19:21 - [INFO|modeling_utils.py:1853] 2023-09-11 10:19:21,425 >> Model weights saved in /mnt/output/checkpoint-450/pytorch_model.bin\n",
      "2023-09-11 10:19:00 - {'loss': 0.0003, 'learning_rate': 6.9e-06, 'epoch': 28.57}\n",
      "2023-09-11 10:19:18 - {'eval_loss': 0.7162216901779175, 'eval_wer': 0.1598477640342531, 'eval_runtime': 18.0036, 'eval_samples_per_second': 3.055, 'eval_steps_per_second': 0.222, 'epoch': 28.57}\n",
      "2023-09-11 10:22:19 - {'loss': 0.0003, 'learning_rate': 6.5875e-06, 'epoch': 30.16}\n",
      "2023-09-11 10:25:12 - {'loss': 0.0002, 'learning_rate': 6.275e-06, 'epoch': 31.75}\n",
      "2023-09-11 10:25:30 - {'eval_loss': 0.722922146320343, 'eval_wer': 0.15794481446241673, 'eval_runtime': 17.9942, 'eval_samples_per_second': 3.057, 'eval_steps_per_second': 0.222, 'epoch': 31.75}\n",
      " 50% 500/1000 [1:02:16<57:43,  6.93s/it][INFO|trainer.py:776] 2023-09-11 10:25:12,401 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:25:12 - [INFO|trainer.py:3205] 2023-09-11 10:25:12,402 >>   Batch size = 8\n",
      "2023-09-11 10:25:12 - [INFO|trainer.py:3202] 2023-09-11 10:25:12,402 >>   Num examples = 55\n",
      "2023-09-11 10:25:12 - [INFO|trainer.py:3200] 2023-09-11 10:25:12,402 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:25:16 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.09s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.29s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.69s/it]\u001b[A\n",
      " 50% 500/1000 [1:02:34<57:43,  6.93s/it]\n",
      "                                        \n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:25:30,447 >> Saving model checkpoint to /mnt/output/checkpoint-500\n",
      "2023-09-11 10:25:30 - [INFO|configuration_utils.py:458] 2023-09-11 10:25:30,448 >> Configuration saved in /mnt/output/checkpoint-500/config.json\n",
      "2023-09-11 10:25:30 - [INFO|configuration_utils.py:364] 2023-09-11 10:25:30,449 >> Configuration saved in /mnt/output/checkpoint-500/generation_config.json\n",
      "2023-09-11 10:25:33 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:25:33,117 >> Feature extractor saved in /mnt/output/checkpoint-500/preprocessor_config.json\n",
      "2023-09-11 10:25:33 - [INFO|modeling_utils.py:1853] 2023-09-11 10:25:33,116 >> Model weights saved in /mnt/output/checkpoint-500/pytorch_model.bin\n",
      "2023-09-11 10:28:31 - {'loss': 0.0002, 'learning_rate': 5.9625e-06, 'epoch': 33.33}\n",
      " 55% 550/1000 [1:08:28<51:53,  6.92s/it][INFO|trainer.py:776] 2023-09-11 10:31:23,936 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:31:23 - {'loss': 0.0002, 'learning_rate': 5.65e-06, 'epoch': 34.92}\n",
      "2023-09-11 10:31:23 - [INFO|trainer.py:3200] 2023-09-11 10:31:23,938 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:31:23 - [INFO|trainer.py:3205] 2023-09-11 10:31:23,938 >>   Batch size = 8\n",
      "2023-09-11 10:31:23 - [INFO|trainer.py:3202] 2023-09-11 10:31:23,938 >>   Num examples = 55\n",
      "2023-09-11 10:31:28 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.28s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.69s/it]\u001b[A\n",
      " 55% 550/1000 [1:08:46<51:53,  6.92s/it]\n",
      "                                        \n",
      "2023-09-11 10:31:41 - {'eval_loss': 0.7282211780548096, 'eval_wer': 0.16270218839200762, 'eval_runtime': 17.9321, 'eval_samples_per_second': 3.067, 'eval_steps_per_second': 0.223, 'epoch': 34.92}\n",
      "2023-09-11 10:31:41 - [INFO|configuration_utils.py:458] 2023-09-11 10:31:41,921 >> Configuration saved in /mnt/output/checkpoint-550/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:31:41,920 >> Saving model checkpoint to /mnt/output/checkpoint-550\n",
      "2023-09-11 10:31:41 - [INFO|configuration_utils.py:364] 2023-09-11 10:31:41,922 >> Configuration saved in /mnt/output/checkpoint-550/generation_config.json\n",
      "2023-09-11 10:31:44 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:31:44,608 >> Feature extractor saved in /mnt/output/checkpoint-550/preprocessor_config.json\n",
      "2023-09-11 10:31:44 - [INFO|modeling_utils.py:1853] 2023-09-11 10:31:44,607 >> Model weights saved in /mnt/output/checkpoint-550/pytorch_model.bin\n",
      "2023-09-11 10:34:42 - {'loss': 0.0002, 'learning_rate': 5.3375e-06, 'epoch': 36.51}\n",
      " 60% 600/1000 [1:14:39<46:02,  6.91s/it][INFO|trainer.py:776] 2023-09-11 10:37:35,359 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:37:35 - [INFO|trainer.py:3205] 2023-09-11 10:37:35,360 >>   Batch size = 8\n",
      "2023-09-11 10:37:35 - [INFO|trainer.py:3202] 2023-09-11 10:37:35,360 >>   Num examples = 55\n",
      "2023-09-11 10:37:35 - [INFO|trainer.py:3200] 2023-09-11 10:37:35,360 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:37:39 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.06s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.28s/it]\u001b[A\n",
      " 60% 600/1000 [1:14:57<46:02,  6.91s/it]\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.69s/it]\u001b[A\n",
      "2023-09-11 10:37:53 - [INFO|configuration_utils.py:458] 2023-09-11 10:37:53,311 >> Configuration saved in /mnt/output/checkpoint-600/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:37:53,310 >> Saving model checkpoint to /mnt/output/checkpoint-600\n",
      "2023-09-11 10:37:53 - [INFO|configuration_utils.py:364] 2023-09-11 10:37:53,312 >> Configuration saved in /mnt/output/checkpoint-600/generation_config.json\n",
      "2023-09-11 10:37:55 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:37:55,981 >> Feature extractor saved in /mnt/output/checkpoint-600/preprocessor_config.json\n",
      "2023-09-11 10:37:55 - [INFO|modeling_utils.py:1853] 2023-09-11 10:37:55,980 >> Model weights saved in /mnt/output/checkpoint-600/pytorch_model.bin\n",
      "2023-09-11 10:37:35 - {'loss': 0.0002, 'learning_rate': 5.025e-06, 'epoch': 38.1}\n",
      "2023-09-11 10:37:53 - {'eval_loss': 0.7321106195449829, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.9472, 'eval_samples_per_second': 3.065, 'eval_steps_per_second': 0.223, 'epoch': 38.1}\n",
      "2023-09-11 10:40:53 - {'loss': 0.0001, 'learning_rate': 4.7125e-06, 'epoch': 39.68}\n",
      " 65% 650/1000 [1:20:50<40:16,  6.90s/it][INFO|trainer.py:776] 2023-09-11 10:43:45,842 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:43:45 - {'loss': 0.0001, 'learning_rate': 4.4e-06, 'epoch': 41.27}\n",
      "2023-09-11 10:43:45 - [INFO|trainer.py:3205] 2023-09-11 10:43:45,844 >>   Batch size = 8\n",
      "2023-09-11 10:43:45 - [INFO|trainer.py:3202] 2023-09-11 10:43:45,844 >>   Num examples = 55\n",
      "2023-09-11 10:43:45 - [INFO|trainer.py:3200] 2023-09-11 10:43:45,844 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:43:50 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.05s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.27s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.68s/it]\u001b[A\n",
      "2023-09-11 10:44:03 - {'eval_loss': 0.7359598875045776, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.8279, 'eval_samples_per_second': 3.085, 'eval_steps_per_second': 0.224, 'epoch': 41.27}\n",
      " 65% 650/1000 [1:21:07<40:16,  6.90s/it]\n",
      "2023-09-11 10:44:03 - [INFO|configuration_utils.py:458] 2023-09-11 10:44:03,723 >> Configuration saved in /mnt/output/checkpoint-650/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:44:03,722 >> Saving model checkpoint to /mnt/output/checkpoint-650\n",
      "2023-09-11 10:44:03 - [INFO|configuration_utils.py:364] 2023-09-11 10:44:03,724 >> Configuration saved in /mnt/output/checkpoint-650/generation_config.json\n",
      "2023-09-11 10:44:06 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:44:06,350 >> Feature extractor saved in /mnt/output/checkpoint-650/preprocessor_config.json\n",
      "2023-09-11 10:44:06 - [INFO|modeling_utils.py:1853] 2023-09-11 10:44:06,349 >> Model weights saved in /mnt/output/checkpoint-650/pytorch_model.bin\n",
      "2023-09-11 10:47:03 - {'loss': 0.0001, 'learning_rate': 4.0875e-06, 'epoch': 42.86}\n",
      " 70% 700/1000 [1:26:59<34:20,  6.87s/it][INFO|trainer.py:776] 2023-09-11 10:49:55,525 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:49:55 - [INFO|trainer.py:3205] 2023-09-11 10:49:55,526 >>   Batch size = 8\n",
      "2023-09-11 10:49:55 - [INFO|trainer.py:3202] 2023-09-11 10:49:55,526 >>   Num examples = 55\n",
      "2023-09-11 10:49:55 - [INFO|trainer.py:3200] 2023-09-11 10:49:55,526 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:49:59 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.05s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.26s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.67s/it]\u001b[A\n",
      " 70% 700/1000 [1:27:17<34:20,  6.87s/it]\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:50:13,353 >> Saving model checkpoint to /mnt/output/checkpoint-700\n",
      "2023-09-11 10:50:13 - [INFO|configuration_utils.py:458] 2023-09-11 10:50:13,354 >> Configuration saved in /mnt/output/checkpoint-700/config.json\n",
      "2023-09-11 10:50:13 - [INFO|configuration_utils.py:364] 2023-09-11 10:50:13,354 >> Configuration saved in /mnt/output/checkpoint-700/generation_config.json\n",
      "2023-09-11 10:50:15 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:50:15,975 >> Feature extractor saved in /mnt/output/checkpoint-700/preprocessor_config.json\n",
      "2023-09-11 10:50:15 - [INFO|modeling_utils.py:1853] 2023-09-11 10:50:15,974 >> Model weights saved in /mnt/output/checkpoint-700/pytorch_model.bin\n",
      "2023-09-11 10:49:55 - {'loss': 0.0001, 'learning_rate': 3.7750000000000003e-06, 'epoch': 44.44}\n",
      "2023-09-11 10:50:13 - {'eval_loss': 0.7390508055686951, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.7759, 'eval_samples_per_second': 3.094, 'eval_steps_per_second': 0.225, 'epoch': 44.44}\n",
      "2023-09-11 10:53:13 - {'loss': 0.0001, 'learning_rate': 3.4625000000000003e-06, 'epoch': 46.03}\n",
      "2023-09-11 10:56:04 - {'loss': 0.0001, 'learning_rate': 3.1500000000000003e-06, 'epoch': 47.62}\n",
      "2023-09-11 10:56:22 - {'eval_loss': 0.7414926290512085, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.844, 'eval_samples_per_second': 3.082, 'eval_steps_per_second': 0.224, 'epoch': 47.62}\n",
      " 75% 750/1000 [1:33:09<28:35,  6.86s/it][INFO|trainer.py:776] 2023-09-11 10:56:04,922 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 10:56:04 - [INFO|trainer.py:3205] 2023-09-11 10:56:04,923 >>   Batch size = 8\n",
      "2023-09-11 10:56:04 - [INFO|trainer.py:3202] 2023-09-11 10:56:04,923 >>   Num examples = 55\n",
      "2023-09-11 10:56:04 - [INFO|trainer.py:3200] 2023-09-11 10:56:04,923 >> ***** Running Evaluation *****\n",
      "2023-09-11 10:56:09 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.06s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.26s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.67s/it]\u001b[A\n",
      " 75% 750/1000 [1:33:27<28:35,  6.86s/it]\n",
      "                                        \n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 10:56:22,818 >> Saving model checkpoint to /mnt/output/checkpoint-750\n",
      "2023-09-11 10:56:22 - [INFO|configuration_utils.py:458] 2023-09-11 10:56:22,819 >> Configuration saved in /mnt/output/checkpoint-750/config.json\n",
      "2023-09-11 10:56:22 - [INFO|configuration_utils.py:364] 2023-09-11 10:56:22,819 >> Configuration saved in /mnt/output/checkpoint-750/generation_config.json\n",
      "2023-09-11 10:56:25 - [INFO|modeling_utils.py:1853] 2023-09-11 10:56:25,456 >> Model weights saved in /mnt/output/checkpoint-750/pytorch_model.bin\n",
      "2023-09-11 10:56:25 - [INFO|feature_extraction_utils.py:377] 2023-09-11 10:56:25,457 >> Feature extractor saved in /mnt/output/checkpoint-750/preprocessor_config.json\n",
      "2023-09-11 10:59:22 - {'loss': 0.0001, 'learning_rate': 2.8375000000000004e-06, 'epoch': 49.21}\n",
      " 80% 800/1000 [1:39:18<22:56,  6.88s/it][INFO|trainer.py:776] 2023-09-11 11:02:14,559 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 11:02:14 - [INFO|trainer.py:3205] 2023-09-11 11:02:14,560 >>   Batch size = 8\n",
      "2023-09-11 11:02:14 - [INFO|trainer.py:3202] 2023-09-11 11:02:14,560 >>   Num examples = 55\n",
      "2023-09-11 11:02:14 - [INFO|trainer.py:3200] 2023-09-11 11:02:14,560 >> ***** Running Evaluation *****\n",
      "2023-09-11 11:02:18 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.08s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.26s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.67s/it]\u001b[A\n",
      "2023-09-11 11:02:32 - [INFO|configuration_utils.py:458] 2023-09-11 11:02:32,446 >> Configuration saved in /mnt/output/checkpoint-800/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 11:02:32,445 >> Saving model checkpoint to /mnt/output/checkpoint-800\n",
      " 80% 800/1000 [1:39:36<22:56,  6.88s/it]\n",
      "2023-09-11 11:02:32 - [INFO|configuration_utils.py:364] 2023-09-11 11:02:32,447 >> Configuration saved in /mnt/output/checkpoint-800/generation_config.json\n",
      "2023-09-11 11:02:35 - [INFO|modeling_utils.py:1853] 2023-09-11 11:02:35,101 >> Model weights saved in /mnt/output/checkpoint-800/pytorch_model.bin\n",
      "2023-09-11 11:02:35 - [INFO|feature_extraction_utils.py:377] 2023-09-11 11:02:35,103 >> Feature extractor saved in /mnt/output/checkpoint-800/preprocessor_config.json\n",
      "2023-09-11 11:02:14 - {'loss': 0.0001, 'learning_rate': 2.5250000000000004e-06, 'epoch': 50.79}\n",
      "2023-09-11 11:02:32 - {'eval_loss': 0.7435091733932495, 'eval_wer': 0.1560418648905804, 'eval_runtime': 17.882, 'eval_samples_per_second': 3.076, 'eval_steps_per_second': 0.224, 'epoch': 50.79}\n",
      "2023-09-11 11:05:32 - {'loss': 0.0001, 'learning_rate': 2.2125e-06, 'epoch': 52.38}\n",
      "2023-09-11 11:08:24 - {'loss': 0.0001, 'learning_rate': 1.9000000000000002e-06, 'epoch': 53.97}\n",
      "2023-09-11 11:08:42 - {'eval_loss': 0.745022177696228, 'eval_wer': 0.1560418648905804, 'eval_runtime': 17.8881, 'eval_samples_per_second': 3.075, 'eval_steps_per_second': 0.224, 'epoch': 53.97}\n",
      " 85% 850/1000 [1:45:28<17:10,  6.87s/it][INFO|trainer.py:776] 2023-09-11 11:08:24,193 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 11:08:24 - [INFO|trainer.py:3205] 2023-09-11 11:08:24,195 >>   Batch size = 8\n",
      "2023-09-11 11:08:24 - [INFO|trainer.py:3202] 2023-09-11 11:08:24,195 >>   Num examples = 55\n",
      "2023-09-11 11:08:24 - [INFO|trainer.py:3200] 2023-09-11 11:08:24,195 >> ***** Running Evaluation *****\n",
      "2023-09-11 11:08:28 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.26s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.67s/it]\u001b[A\n",
      "                                        \n",
      "2023-09-11 11:08:42 - [INFO|configuration_utils.py:364] 2023-09-11 11:08:42,087 >> Configuration saved in /mnt/output/checkpoint-850/generation_config.json\n",
      "2023-09-11 11:08:42 - [INFO|configuration_utils.py:458] 2023-09-11 11:08:42,086 >> Configuration saved in /mnt/output/checkpoint-850/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 11:08:42,085 >> Saving model checkpoint to /mnt/output/checkpoint-850\n",
      " 85% 850/1000 [1:45:46<17:10,  6.87s/it]\n",
      "2023-09-11 11:08:44 - [INFO|modeling_utils.py:1853] 2023-09-11 11:08:44,746 >> Model weights saved in /mnt/output/checkpoint-850/pytorch_model.bin\n",
      "2023-09-11 11:08:44 - [INFO|feature_extraction_utils.py:377] 2023-09-11 11:08:44,747 >> Feature extractor saved in /mnt/output/checkpoint-850/preprocessor_config.json\n",
      "2023-09-11 11:11:41 - {'loss': 0.0001, 'learning_rate': 1.5875e-06, 'epoch': 55.56}\n",
      " 90% 900/1000 [1:51:37<11:25,  6.86s/it][INFO|trainer.py:776] 2023-09-11 11:14:33,655 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-11 11:14:33 - [INFO|trainer.py:3205] 2023-09-11 11:14:33,657 >>   Batch size = 8\n",
      "2023-09-11 11:14:33 - [INFO|trainer.py:3202] 2023-09-11 11:14:33,657 >>   Num examples = 55\n",
      "2023-09-11 11:14:33 - [INFO|trainer.py:3200] 2023-09-11 11:14:33,656 >> ***** Running Evaluation *****\n",
      "2023-09-11 11:14:38 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.26s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.66s/it]\u001b[A\n",
      " 90% 900/1000 [1:51:55<11:25,  6.86s/it]\n",
      "                                        \n",
      "2023-09-11 11:14:51 - [INFO|configuration_utils.py:458] 2023-09-11 11:14:51,517 >> Configuration saved in /mnt/output/checkpoint-900/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-11 11:14:51,516 >> Saving model checkpoint to /mnt/output/checkpoint-900\n",
      "2023-09-11 11:14:51 - [INFO|configuration_utils.py:364] 2023-09-11 11:14:51,517 >> Configuration saved in /mnt/output/checkpoint-900/generation_config.json\n",
      "2023-09-11 11:14:54 - [INFO|modeling_utils.py:1853] 2023-09-11 11:14:54,156 >> Model weights saved in /mnt/output/checkpoint-900/pytorch_model.bin\n",
      "2023-09-11 11:14:54 - [INFO|feature_extraction_utils.py:377] 2023-09-11 11:14:54,157 >> Feature extractor saved in /mnt/output/checkpoint-900/preprocessor_config.json\n",
      "2023-09-11 11:14:33 - {'loss': 0.0001, 'learning_rate': 1.275e-06, 'epoch': 57.14}\n",
      "2023-09-11 11:14:51 - {'eval_loss': 0.7461679577827454, 'eval_wer': 0.1560418648905804, 'eval_runtime': 17.8567, 'eval_samples_per_second': 3.08, 'eval_steps_per_second': 0.224, 'epoch': 57.14}\n"
     ]
    }
   ],
   "source": [
    "job_run.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "job_run.watch()\n",
    "\n",
    "with open('output1000_atco2.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
