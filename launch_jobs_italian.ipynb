{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3157b507",
   "metadata": {},
   "source": [
    "### Launch Jobs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209c7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ads\n",
    "\n",
    "from ads.jobs import DataScienceJob\n",
    "from ads.jobs import DataScienceJobRun\n",
    "from ads.jobs import ScriptRuntime\n",
    "from ads.jobs import Job\n",
    "\n",
    "from ads import set_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55a9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "# project_id = os.environ['PROJECT_OCID']\n",
    "\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4be0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here all the definitions\n",
    "#\n",
    "LOG_GROUP_ID = \"ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyazs4l4rzrzsarlej6mqlwlbz6bmnx4adwdlssveam2jaa\"\n",
    "LOG_ID = \"ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdya47httqmxyiew5tkxa6l7gekev2ljpasixuhmp2fa3v5q\"\n",
    "\n",
    "NAMESPACE = \"frqap2zhtzbe\"\n",
    "CONDA_BUCKET = \"whisper_jobs_env\"\n",
    "# bucket with code to execute\n",
    "SOURCE_BUCKET = \"whisper_jobs\"\n",
    "\n",
    "CUSTOM_ENV_URI = f\"oci://{CONDA_BUCKET}@{NAMESPACE}/conda_environments/gpu/whisper_env_/1.0/whisper_env_v1_0\"\n",
    "SOURCE_URI = f\"oci://{SOURCE_BUCKET}@{NAMESPACE}/test_atco2.tar.gz\"\n",
    "\n",
    "# the first to execute\n",
    "RUN_ENTRYPOINT = \"train.sh\"\n",
    "\n",
    "# SHAPE_NAME = \"VM.Standard2.4\"\n",
    "# SHAPE_NAME = \"VM.GPU2.1\"\n",
    "SHAPE_NAME = \"VM.GPU.A10.2\"\n",
    "# in GB\n",
    "STORAGE_SIZE = 2000\n",
    "\n",
    "JOBS_NAME = \"job_atco2_002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645b326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Specify the Infrastructure requested\n",
    "# VM Shape, logging\n",
    "# network is taken from NB session\n",
    "\n",
    "# you need to provide the OCID for LogGroup and Log\n",
    "infrastructure = (\n",
    "    DataScienceJob()\n",
    "    .with_shape_name(SHAPE_NAME)\n",
    "    .with_block_storage_size(STORAGE_SIZE)\n",
    "    .with_log_group_id(LOG_GROUP_ID)\n",
    "    .with_log_id(LOG_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60adc820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the runtime and conda and env \n",
    "runtime = (\n",
    "    ScriptRuntime()\n",
    "    .with_source(SOURCE_URI)\n",
    "    .with_custom_conda(CUSTOM_ENV_URI)\n",
    "    .with_environment_variable(JOB_RUN_ENTRYPOINT=RUN_ENTRYPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0fe00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the JOB\n",
    "job = (\n",
    "    Job(name=JOBS_NAME)\n",
    "    .with_infrastructure(infrastructure)\n",
    "    .with_runtime(runtime)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f127f290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kind: job\n",
       "spec:\n",
       "  id: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyaacxhlu5fpxi4cle2iahvyfkkkp2ynpmqykrhq4ymsyla\n",
       "  infrastructure:\n",
       "    kind: infrastructure\n",
       "    spec:\n",
       "      blockStorageSize: 2000\n",
       "      compartmentId: ocid1.compartment.oc1..aaaaaaaag2cpni5qj6li5ny6ehuahhepbpveopobooayqfeudqygdtfe6h3a\n",
       "      displayName: job_atco2_002\n",
       "      jobInfrastructureType: STANDALONE\n",
       "      jobType: DEFAULT\n",
       "      logGroupId: ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyazs4l4rzrzsarlej6mqlwlbz6bmnx4adwdlssveam2jaa\n",
       "      logId: ocid1.log.oc1.eu-frankfurt-1.amaaaaaangencdya47httqmxyiew5tkxa6l7gekev2ljpasixuhmp2fa3v5q\n",
       "      projectId: ocid1.datascienceproject.oc1.eu-frankfurt-1.amaaaaaangencdyasybymsgwfmwo7ukyjs6kdl573kpxnb5rgy52c5irb5pq\n",
       "      shapeName: VM.GPU.A10.2\n",
       "      subnetId: ocid1.subnet.oc1.eu-frankfurt-1.aaaaaaaaijgqblnhpqle2zorl75qli23wre5eboqjtystagdgun4qwdxj4aq\n",
       "    type: dataScienceJob\n",
       "  name: job_atco2_002\n",
       "  runtime:\n",
       "    kind: runtime\n",
       "    spec:\n",
       "      conda:\n",
       "        type: published\n",
       "        uri: oci://whisper_jobs_env@frqap2zhtzbe/conda_environments/gpu/whisper_env_/1.0/whisper_env_v1_0\n",
       "      env:\n",
       "      - name: JOB_RUN_ENTRYPOINT\n",
       "        value: train.sh\n",
       "      scriptPathURI: oci://whisper_jobs@frqap2zhtzbe/test_atco2.tar.gz\n",
       "    type: script"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the JOB\n",
    "job.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f2eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the job run by id\n",
    "# JOB_RUN_OCID = \"ocid1.datasciencejobrun.oc1.eu-frankfurt-1.amaaaaaangencdyais5w2gkzbqbwqeftps6raay65ymhg46hltw3vlokij3q\"\n",
    "\n",
    "# job_run = DataScienceJobRun.from_ocid(JOB_RUN_OCID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca88c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run = job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ce98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job OCID: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyaacxhlu5fpxi4cle2iahvyfkkkp2ynpmqykrhq4ymsyla\n",
      "Job Run OCID: ocid1.datasciencejobrun.oc1.eu-frankfurt-1.amaaaaaangencdyarxhsxkarfcos73iv2valxxbyoth4cnrjjk5jda4pdrqa\n",
      "2023-09-07 09:36:01 - Job Run ACCEPTED\n",
      "2023-09-07 09:36:11 - Job Run ACCEPTED, Infrastructure provisioning.\n",
      "2023-09-07 09:37:35 - Job Run ACCEPTED, Infrastructure provisioned.\n",
      "2023-09-07 09:38:00 - Job Run ACCEPTED, Job run bootstrap starting.\n",
      "2023-09-07 09:41:19 - Job Run ACCEPTED, Job run bootstrap complete. Artifact execution starting.\n",
      "2023-09-07 09:41:25 - Job Run IN_PROGRESS, Job run artifact execution in progress.\n",
      "2023-09-07 09:41:20 - *****************************************\n",
      "2023-09-07 09:41:20 - WARNING:torch.distributed.run:\n",
      "2023-09-07 09:41:20 - *****************************************\n",
      "2023-09-07 09:41:20 - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "2023-09-07 09:41:20 - Fontconfig error: Cannot load default config file: No such file: (null)\n",
      "2023-09-07 09:41:20 - Fontconfig error: Cannot load default config file: No such file: (null)\n",
      "Downloading metadata: 100% 806/806 [00:00<00:00, 1.47MB/s]\n",
      "Downloading metadata: 100% 806/806 [00:00<00:00, 1.59MB/s]\n",
      "Downloading readme: 100% 220/220 [00:00<00:00, 474kB/s]\n",
      "Downloading readme: 100% 220/220 [00:00<00:00, 440kB/s]\n",
      "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   7% 8.07M/113M [00:00<00:01, 80.7MB/s]\u001b[A\n",
      "Downloading data:  17% 19.1M/113M [00:00<00:00, 98.2MB/s]\u001b[A\n",
      "Downloading data:  27% 30.3M/113M [00:00<00:00, 104MB/s] \u001b[A\n",
      "Downloading data:  37% 41.5M/113M [00:00<00:00, 107MB/s]\u001b[A\n",
      "Downloading data:  47% 52.6M/113M [00:00<00:00, 109MB/s]\u001b[A\n",
      "Downloading data:  57% 63.7M/113M [00:00<00:00, 110MB/s]\u001b[A\n",
      "Downloading data:  66% 74.7M/113M [00:00<00:00, 110MB/s]\u001b[A\n",
      "Downloading data:  76% 85.8M/113M [00:00<00:00, 110MB/s]\u001b[A\n",
      "Downloading data:  86% 97.0M/113M [00:00<00:00, 111MB/s]\u001b[A\n",
      "Downloading data: 100% 113M/113M [00:01<00:00, 108MB/s] \u001b[A\n",
      "Downloading data files:  50% 1/2 [00:01<00:01,  1.39s/it]\n",
      "Downloading data:   0% 0.00/13.2M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data files: 100% 2/2 [00:01<00:00,  1.07it/s]\n",
      "Downloading data: 100% 13.2M/13.2M [00:00<00:00, 88.0MB/s]\u001b[A\n",
      "Extracting data files: 100% 2/2 [00:00<00:00, 2342.53it/s]\n",
      "Downloading (â€¦)lve/main/config.json: 100% 1.99k/1.99k [00:00<00:00, 910kB/s]\n",
      "2023-09-07 09:41:29 - [INFO|configuration_utils.py:669] 2023-09-07 09:41:29,616 >> loading configuration file config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/config.json\n",
      "2023-09-07 09:41:29 -   \"activation_dropout\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"_name_or_path\": \"openai/whisper-medium\",\n",
      "2023-09-07 09:41:29 - [INFO|configuration_utils.py:725] 2023-09-07 09:41:29,620 >> Model config WhisperConfig {\n",
      "2023-09-07 09:41:29 -   ],\n",
      "2023-09-07 09:41:29 -     \"WhisperForConditionalGeneration\"\n",
      "2023-09-07 09:41:29 -   \"architectures\": [\n",
      "2023-09-07 09:41:29 -   \"apply_spec_augment\": false,\n",
      "2023-09-07 09:41:29 -   \"activation_function\": \"gelu\",\n",
      "2023-09-07 09:41:29 -   \"bos_token_id\": 50257,\n",
      "2023-09-07 09:41:29 -   ],\n",
      "2023-09-07 09:41:29 -     50257\n",
      "2023-09-07 09:41:29 -     220,\n",
      "2023-09-07 09:41:29 -   \"begin_suppress_tokens\": [\n",
      "2023-09-07 09:41:29 -   \"attention_dropout\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"decoder_layerdrop\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"decoder_ffn_dim\": 4096,\n",
      "2023-09-07 09:41:29 -   \"decoder_attention_heads\": 16,\n",
      "2023-09-07 09:41:29 -   \"d_model\": 1024,\n",
      "2023-09-07 09:41:29 -   \"classifier_proj_size\": 256,\n",
      "2023-09-07 09:41:29 -   \"encoder_layerdrop\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"encoder_ffn_dim\": 4096,\n",
      "2023-09-07 09:41:29 -   \"encoder_attention_heads\": 16,\n",
      "2023-09-07 09:41:29 -   \"dropout\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-07 09:41:29 -   \"decoder_layers\": 24,\n",
      "2023-09-07 09:41:29 -     ],\n",
      "2023-09-07 09:41:29 -       50259\n",
      "2023-09-07 09:41:29 -       1,\n",
      "2023-09-07 09:41:29 -     [\n",
      "2023-09-07 09:41:29 -   \"forced_decoder_ids\": [\n",
      "2023-09-07 09:41:29 -   \"eos_token_id\": 50257,\n",
      "2023-09-07 09:41:29 -   \"encoder_layers\": 24,\n",
      "2023-09-07 09:41:29 -     [\n",
      "2023-09-07 09:41:29 -     ],\n",
      "2023-09-07 09:41:29 -       50359\n",
      "2023-09-07 09:41:29 -       2,\n",
      "2023-09-07 09:41:29 -     [\n",
      "2023-09-07 09:41:29 -   \"init_std\": 0.02,\n",
      "2023-09-07 09:41:29 -   ],\n",
      "2023-09-07 09:41:29 -     ]\n",
      "2023-09-07 09:41:29 -       50363\n",
      "2023-09-07 09:41:29 -       3,\n",
      "2023-09-07 09:41:29 -   \"mask_time_min_masks\": 2,\n",
      "2023-09-07 09:41:29 -   \"mask_time_length\": 10,\n",
      "2023-09-07 09:41:29 -   \"mask_feature_prob\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"mask_feature_min_masks\": 0,\n",
      "2023-09-07 09:41:29 -   \"mask_feature_length\": 10,\n",
      "2023-09-07 09:41:29 -   \"is_encoder_decoder\": true,\n",
      "2023-09-07 09:41:29 -   \"model_type\": \"whisper\",\n",
      "2023-09-07 09:41:29 -   \"max_target_positions\": 448,\n",
      "2023-09-07 09:41:29 -   \"max_source_positions\": 1500,\n",
      "2023-09-07 09:41:29 -   \"max_length\": 448,\n",
      "2023-09-07 09:41:29 -   \"mask_time_prob\": 0.05,\n",
      "2023-09-07 09:41:29 -     2,\n",
      "2023-09-07 09:41:29 -     1,\n",
      "2023-09-07 09:41:29 -   \"suppress_tokens\": [\n",
      "2023-09-07 09:41:29 -   \"scale_embedding\": false,\n",
      "2023-09-07 09:41:29 -   \"pad_token_id\": 50257,\n",
      "2023-09-07 09:41:29 -   \"num_mel_bins\": 80,\n",
      "2023-09-07 09:41:29 -   \"num_hidden_layers\": 24,\n",
      "2023-09-07 09:41:29 -     14,\n",
      "2023-09-07 09:41:29 -     10,\n",
      "2023-09-07 09:41:29 -     9,\n",
      "2023-09-07 09:41:29 -     8,\n",
      "2023-09-07 09:41:29 -     7,\n",
      "2023-09-07 09:41:29 -     31,\n",
      "2023-09-07 09:41:29 -     29,\n",
      "2023-09-07 09:41:29 -     28,\n",
      "2023-09-07 09:41:29 -     27,\n",
      "2023-09-07 09:41:29 -     26,\n",
      "2023-09-07 09:41:29 -     25,\n",
      "2023-09-07 09:41:29 -     62,\n",
      "2023-09-07 09:41:29 -     61,\n",
      "2023-09-07 09:41:29 -     60,\n",
      "2023-09-07 09:41:29 -     59,\n",
      "2023-09-07 09:41:29 -     58,\n",
      "2023-09-07 09:41:29 -     503,\n",
      "2023-09-07 09:41:29 -     359,\n",
      "2023-09-07 09:41:29 -     93,\n",
      "2023-09-07 09:41:29 -     92,\n",
      "2023-09-07 09:41:29 -     91,\n",
      "2023-09-07 09:41:29 -     90,\n",
      "2023-09-07 09:41:29 -     63,\n",
      "2023-09-07 09:41:29 -     902,\n",
      "2023-09-07 09:41:29 -     893,\n",
      "2023-09-07 09:41:29 -     873,\n",
      "2023-09-07 09:41:29 -     542,\n",
      "2023-09-07 09:41:29 -     522,\n",
      "2023-09-07 09:41:29 -     1853,\n",
      "2023-09-07 09:41:29 -     1350,\n",
      "2023-09-07 09:41:29 -     931,\n",
      "2023-09-07 09:41:29 -     922,\n",
      "2023-09-07 09:41:29 -     918,\n",
      "2023-09-07 09:41:29 -     3253,\n",
      "2023-09-07 09:41:29 -     3246,\n",
      "2023-09-07 09:41:29 -     2627,\n",
      "2023-09-07 09:41:29 -     2460,\n",
      "2023-09-07 09:41:29 -     1982,\n",
      "2023-09-07 09:41:29 -     6585,\n",
      "2023-09-07 09:41:29 -     4667,\n",
      "2023-09-07 09:41:29 -     4183,\n",
      "2023-09-07 09:41:29 -     3961,\n",
      "2023-09-07 09:41:29 -     3846,\n",
      "2023-09-07 09:41:29 -     3536,\n",
      "2023-09-07 09:41:29 -     3268,\n",
      "2023-09-07 09:41:29 -     10428,\n",
      "2023-09-07 09:41:29 -     9383,\n",
      "2023-09-07 09:41:29 -     9061,\n",
      "2023-09-07 09:41:29 -     7273,\n",
      "2023-09-07 09:41:29 -     6647,\n",
      "2023-09-07 09:41:29 -     14157,\n",
      "2023-09-07 09:41:29 -     13793,\n",
      "2023-09-07 09:41:29 -     12562,\n",
      "2023-09-07 09:41:29 -     12331,\n",
      "2023-09-07 09:41:29 -     12033,\n",
      "2023-09-07 09:41:29 -     11938,\n",
      "2023-09-07 09:41:29 -     10929,\n",
      "2023-09-07 09:41:29 -     16604,\n",
      "2023-09-07 09:41:29 -     16553,\n",
      "2023-09-07 09:41:29 -     15618,\n",
      "2023-09-07 09:41:29 -     15265,\n",
      "2023-09-07 09:41:29 -     14635,\n",
      "2023-09-07 09:41:29 -     26130,\n",
      "2023-09-07 09:41:29 -     22520,\n",
      "2023-09-07 09:41:29 -     21675,\n",
      "2023-09-07 09:41:29 -     20075,\n",
      "2023-09-07 09:41:29 -     18956,\n",
      "2023-09-07 09:41:29 -     18362,\n",
      "2023-09-07 09:41:29 -     31650,\n",
      "2023-09-07 09:41:29 -     29464,\n",
      "2023-09-07 09:41:29 -     28279,\n",
      "2023-09-07 09:41:29 -     26435,\n",
      "2023-09-07 09:41:29 -     26161,\n",
      "2023-09-07 09:41:29 -     49870,\n",
      "2023-09-07 09:41:29 -     47425,\n",
      "2023-09-07 09:41:29 -     42863,\n",
      "2023-09-07 09:41:29 -     36865,\n",
      "2023-09-07 09:41:29 -     32470,\n",
      "2023-09-07 09:41:29 -     32302,\n",
      "2023-09-07 09:41:29 -     50361,\n",
      "2023-09-07 09:41:29 -     50360,\n",
      "2023-09-07 09:41:29 -     50359,\n",
      "2023-09-07 09:41:29 -     50358,\n",
      "2023-09-07 09:41:29 -     50258,\n",
      "2023-09-07 09:41:29 -     50254,\n",
      "2023-09-07 09:41:29 -   \"torch_dtype\": \"float32\",\n",
      "2023-09-07 09:41:29 -   ],\n",
      "2023-09-07 09:41:29 -     50362\n",
      "2023-09-07 09:41:29 -   \"vocab_size\": 51865\n",
      "2023-09-07 09:41:29 -   \"use_weighted_layer_sum\": false,\n",
      "2023-09-07 09:41:29 -   \"use_cache\": true,\n",
      "2023-09-07 09:41:29 -   \"transformers_version\": \"4.30.2\",\n",
      "2023-09-07 09:41:29 - \n",
      "2023-09-07 09:41:29 - }\n",
      "Downloading (â€¦)rocessor_config.json: 100% 185k/185k [00:00<00:00, 2.03MB/s]\n",
      "2023-09-07 09:41:29 - [INFO|feature_extraction_utils.py:477] 2023-09-07 09:41:29,929 >> loading configuration file preprocessor_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/preprocessor_config.json\n",
      "2023-09-07 09:41:29 -   \"hop_length\": 160,\n",
      "2023-09-07 09:41:29 -   \"feature_size\": 80,\n",
      "2023-09-07 09:41:29 -   \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "2023-09-07 09:41:29 -   \"chunk_length\": 30,\n",
      "2023-09-07 09:41:29 - [INFO|feature_extraction_utils.py:519] 2023-09-07 09:41:29,931 >> Feature extractor WhisperFeatureExtractor {\n",
      "2023-09-07 09:41:29 -   \"processor_class\": \"WhisperProcessor\",\n",
      "2023-09-07 09:41:29 -   \"padding_value\": 0.0,\n",
      "2023-09-07 09:41:29 -   \"padding_side\": \"right\",\n",
      "2023-09-07 09:41:29 -   \"nb_max_frames\": 3000,\n",
      "2023-09-07 09:41:29 -   \"n_samples\": 480000,\n",
      "2023-09-07 09:41:29 -   \"n_fft\": 400,\n",
      "2023-09-07 09:41:29 - \n",
      "2023-09-07 09:41:29 - }\n",
      "2023-09-07 09:41:29 -   \"sampling_rate\": 16000\n",
      "2023-09-07 09:41:29 -   \"return_attention_mask\": false,\n",
      "Downloading (â€¦)okenizer_config.json: 100% 843/843 [00:00<00:00, 842kB/s]\n",
      "Downloading (â€¦)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 2.84MB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100% 2.20M/2.20M [00:00<00:00, 4.87MB/s]\n",
      "Downloading (â€¦)olve/main/merges.txt: 100% 494k/494k [00:00<00:00, 1.82MB/s]\n",
      "Downloading (â€¦)main/normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 59.0MB/s]\n",
      "Downloading (â€¦)in/added_tokens.json: 100% 2.08k/2.08k [00:00<00:00, 2.64MB/s]\n",
      "Downloading (â€¦)cial_tokens_map.json: 100% 2.08k/2.08k [00:00<00:00, 2.75MB/s]\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file tokenizer.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/tokenizer.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file vocab.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/vocab.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file tokenizer_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/tokenizer_config.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file special_tokens_map.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/special_tokens_map.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file added_tokens.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/added_tokens.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file normalizer.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/normalizer.json\n",
      "2023-09-07 09:41:32 - [INFO|tokenization_utils_base.py:1823] 2023-09-07 09:41:32,797 >> loading file merges.txt from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/merges.txt\n",
      "Downloading model.safetensors: 100% 3.06G/3.06G [00:13<00:00, 231MB/s] \n",
      "2023-09-07 09:41:46 - [INFO|modeling_utils.py:2578] 2023-09-07 09:41:46,263 >> loading weights file model.safetensors from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/model.safetensors\n",
      "2023-09-07 09:41:46 -   \"_from_model_config\": true,\n",
      "2023-09-07 09:41:46 - [INFO|configuration_utils.py:577] 2023-09-07 09:41:46,394 >> Generate config GenerationConfig {\n",
      "2023-09-07 09:41:46 -   ],\n",
      "2023-09-07 09:41:46 -     50257\n",
      "2023-09-07 09:41:46 -     220,\n",
      "2023-09-07 09:41:46 -   \"begin_suppress_tokens\": [\n",
      "2023-09-07 09:41:46 -   \"transformers_version\": \"4.30.2\"\n",
      "2023-09-07 09:41:46 -   \"pad_token_id\": 50257,\n",
      "2023-09-07 09:41:46 -   \"max_length\": 448,\n",
      "2023-09-07 09:41:46 -   \"eos_token_id\": 50257,\n",
      "2023-09-07 09:41:46 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-07 09:41:46 -   \"bos_token_id\": 50257,\n",
      "2023-09-07 09:41:46 - \n",
      "2023-09-07 09:41:46 - }\n",
      "2023-09-07 09:41:24 - Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "2023-09-07 09:41:24 - Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "2023-09-07 09:41:24 - Login successful\n",
      "2023-09-07 09:41:24 - Your token has been saved to /home/datascience/.cache/huggingface/token\n",
      "2023-09-07 09:41:24 - Token is valid (permission: write).\n",
      "2023-09-07 09:41:24 - Login successful\n",
      "2023-09-07 09:41:24 - Your token has been saved to /home/datascience/.cache/huggingface/token\n",
      "2023-09-07 09:41:24 - Token is valid (permission: write).\n",
      "2023-09-07 09:41:24 - 09/07/2023 09:41:24 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "2023-09-07 09:41:24 - adam_epsilon=1e-08,\n",
      "2023-09-07 09:41:24 - adam_beta2=0.999,\n",
      "2023-09-07 09:41:24 - adam_beta1=0.9,\n",
      "2023-09-07 09:41:24 - adafactor=False,\n",
      "2023-09-07 09:41:24 - _n_gpu=1,\n",
      "2023-09-07 09:41:24 - 09/07/2023 09:41:24 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "2023-09-07 09:41:24 - auto_find_batch_size=False,\n",
      "2023-09-07 09:41:24 - ddp_timeout=1800,\n",
      "2023-09-07 09:41:24 - ddp_find_unused_parameters=None,\n",
      "2023-09-07 09:41:24 - ddp_bucket_cap_mb=None,\n",
      "2023-09-07 09:41:24 - ddp_backend=None,\n",
      "2023-09-07 09:41:24 - dataloader_pin_memory=True,\n",
      "2023-09-07 09:41:24 - dataloader_num_workers=0,\n",
      "2023-09-07 09:41:24 - dataloader_drop_last=False,\n",
      "2023-09-07 09:41:24 - data_seed=None,\n",
      "2023-09-07 09:41:24 - bf16_full_eval=False,\n",
      "2023-09-07 09:41:24 - bf16=False,\n",
      "2023-09-07 09:41:24 - do_eval=True,\n",
      "2023-09-07 09:41:24 - disable_tqdm=False,\n",
      "2023-09-07 09:41:24 - deepspeed=None,\n",
      "2023-09-07 09:41:24 - debug=[],\n",
      "2023-09-07 09:41:24 - fp16_full_eval=False,\n",
      "2023-09-07 09:41:24 - fp16_backend=auto,\n",
      "2023-09-07 09:41:24 - fp16=True,\n",
      "2023-09-07 09:41:24 - evaluation_strategy=steps,\n",
      "2023-09-07 09:41:24 - eval_steps=50,\n",
      "2023-09-07 09:41:24 - eval_delay=0,\n",
      "2023-09-07 09:41:24 - eval_accumulation_steps=None,\n",
      "2023-09-07 09:41:24 - do_train=True,\n",
      "2023-09-07 09:41:24 - do_predict=False,\n",
      "2023-09-07 09:41:24 - full_determinism=False,\n",
      "2023-09-07 09:41:24 - fsdp_transformer_layer_cls_to_wrap=None,\n",
      "2023-09-07 09:41:24 - fsdp_min_num_params=0,\n",
      "2023-09-07 09:41:24 - fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "2023-09-07 09:41:24 - fsdp=[],\n",
      "2023-09-07 09:41:24 - fp16_opt_level=O1,\n",
      "2023-09-07 09:41:24 - generation_max_length=225,\n",
      "2023-09-07 09:41:24 - generation_config=None,\n",
      "2023-09-07 09:41:24 - greater_is_better=None,\n",
      "2023-09-07 09:41:24 - gradient_checkpointing=True,\n",
      "2023-09-07 09:41:24 - gradient_accumulation_steps=8,\n",
      "2023-09-07 09:41:24 - generation_num_beams=None,\n",
      "2023-09-07 09:41:24 - ignore_data_skip=False,\n",
      "2023-09-07 09:41:24 - hub_token=<HUB_TOKEN>,\n",
      "2023-09-07 09:41:24 - hub_strategy=every_save,\n",
      "2023-09-07 09:41:24 - hub_private_repo=False,\n",
      "2023-09-07 09:41:24 - hub_model_id=None,\n",
      "2023-09-07 09:41:24 - half_precision_backend=auto,\n",
      "2023-09-07 09:41:24 - group_by_length=False,\n",
      "2023-09-07 09:41:24 - log_level_replica=warning,\n",
      "2023-09-07 09:41:24 - log_level=passive,\n",
      "2023-09-07 09:41:24 - local_rank=0,\n",
      "2023-09-07 09:41:24 - load_best_model_at_end=False,\n",
      "2023-09-07 09:41:24 - length_column_name=input_length,\n",
      "2023-09-07 09:41:24 - learning_rate=1e-05,\n",
      "2023-09-07 09:41:24 - label_smoothing_factor=0.0,\n",
      "2023-09-07 09:41:24 - label_names=None,\n",
      "2023-09-07 09:41:24 - jit_mode_eval=False,\n",
      "2023-09-07 09:41:24 - include_inputs_for_metrics=False,\n",
      "2023-09-07 09:41:24 - max_grad_norm=1.0,\n",
      "2023-09-07 09:41:24 - lr_scheduler_type=linear,\n",
      "2023-09-07 09:41:24 - logging_strategy=steps,\n",
      "2023-09-07 09:41:24 - logging_steps=25,\n",
      "2023-09-07 09:41:24 - logging_nan_inf_filter=True,\n",
      "2023-09-07 09:41:24 - logging_first_step=False,\n",
      "2023-09-07 09:41:24 - logging_dir=/mnt/output/runs/Sep07_09-41-24_c75c86adb29f,\n",
      "2023-09-07 09:41:24 - log_on_each_node=True,\n",
      "2023-09-07 09:41:24 - overwrite_output_dir=True,\n",
      "2023-09-07 09:41:24 - output_dir=/mnt/output,\n",
      "2023-09-07 09:41:24 - optim_args=None,\n",
      "2023-09-07 09:41:24 - optim=adamw_hf,\n",
      "2023-09-07 09:41:24 - num_train_epochs=3.0,\n",
      "2023-09-07 09:41:24 - no_cuda=False,\n",
      "2023-09-07 09:41:24 - mp_parameters=,\n",
      "2023-09-07 09:41:24 - metric_for_best_model=None,\n",
      "2023-09-07 09:41:24 - max_steps=1000,\n",
      "2023-09-07 09:41:24 - push_to_hub_organization=None,\n",
      "2023-09-07 09:41:24 - push_to_hub_model_id=None,\n",
      "2023-09-07 09:41:24 - push_to_hub=False,\n",
      "2023-09-07 09:41:24 - prediction_loss_only=False,\n",
      "2023-09-07 09:41:24 - predict_with_generate=True,\n",
      "2023-09-07 09:41:24 - per_device_train_batch_size=2,\n",
      "2023-09-07 09:41:24 - per_device_eval_batch_size=8,\n",
      "2023-09-07 09:41:24 - past_index=-1,\n",
      "2023-09-07 09:41:24 - save_on_each_node=False,\n",
      "2023-09-07 09:41:24 - run_name=/mnt/output,\n",
      "2023-09-07 09:41:24 - resume_from_checkpoint=None,\n",
      "2023-09-07 09:41:24 - report_to=['mlflow', 'tensorboard'],\n",
      "2023-09-07 09:41:24 - remove_unused_columns=True,\n",
      "2023-09-07 09:41:24 - ray_scope=last,\n",
      "2023-09-07 09:41:24 - push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "2023-09-07 09:41:24 - torch_compile_backend=None,\n",
      "2023-09-07 09:41:24 - torch_compile=False,\n",
      "2023-09-07 09:41:24 - tf32=None,\n",
      "2023-09-07 09:41:24 - sortish_sampler=False,\n",
      "2023-09-07 09:41:24 - skip_memory_metrics=True,\n",
      "2023-09-07 09:41:24 - sharded_ddp=[],\n",
      "2023-09-07 09:41:24 - seed=42,\n",
      "2023-09-07 09:41:24 - save_total_limit=None,\n",
      "2023-09-07 09:41:24 - save_strategy=steps,\n",
      "2023-09-07 09:41:24 - save_steps=50,\n",
      "2023-09-07 09:41:24 - save_safetensors=False,\n",
      "2023-09-07 09:41:24 - tpu_num_cores=None,\n",
      "2023-09-07 09:41:24 - tpu_metrics_debug=False,\n",
      "2023-09-07 09:41:24 - torchdynamo=None,\n",
      "2023-09-07 09:41:24 - torch_compile_mode=None,\n",
      "2023-09-07 09:41:24 - )\n",
      "2023-09-07 09:41:24 - xpu_backend=None,\n",
      "2023-09-07 09:41:24 - weight_decay=0.0,\n",
      "2023-09-07 09:41:24 - warmup_steps=200,\n",
      "2023-09-07 09:41:24 - warmup_ratio=0.0,\n",
      "2023-09-07 09:41:24 - use_mps_device=False,\n",
      "2023-09-07 09:41:24 - use_legacy_prediction_loop=False,\n",
      "2023-09-07 09:41:24 - use_ipex=False,\n",
      "2023-09-07 09:41:24 - data_seed=None,\n",
      "2023-09-07 09:41:24 - bf16_full_eval=False,\n",
      "2023-09-07 09:41:24 - bf16=False,\n",
      "2023-09-07 09:41:24 - auto_find_batch_size=False,\n",
      "2023-09-07 09:41:24 - adam_epsilon=1e-08,\n",
      "2023-09-07 09:41:24 - adam_beta2=0.999,\n",
      "2023-09-07 09:41:24 - adam_beta1=0.9,\n",
      "2023-09-07 09:41:24 - adafactor=False,\n",
      "2023-09-07 09:41:24 - _n_gpu=1,\n",
      "2023-09-07 09:41:24 - 09/07/2023 09:41:24 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "2023-09-07 09:41:24 - ddp_timeout=1800,\n",
      "2023-09-07 09:41:24 - ddp_find_unused_parameters=None,\n",
      "2023-09-07 09:41:24 - ddp_bucket_cap_mb=None,\n",
      "2023-09-07 09:41:24 - ddp_backend=None,\n",
      "2023-09-07 09:41:24 - dataloader_pin_memory=True,\n",
      "2023-09-07 09:41:24 - dataloader_num_workers=0,\n",
      "2023-09-07 09:41:24 - dataloader_drop_last=False,\n",
      "2023-09-07 09:41:24 - evaluation_strategy=steps,\n",
      "2023-09-07 09:41:24 - eval_steps=50,\n",
      "2023-09-07 09:41:24 - eval_delay=0,\n",
      "2023-09-07 09:41:24 - eval_accumulation_steps=None,\n",
      "2023-09-07 09:41:24 - do_train=True,\n",
      "2023-09-07 09:41:24 - do_predict=False,\n",
      "2023-09-07 09:41:24 - do_eval=True,\n",
      "2023-09-07 09:41:24 - disable_tqdm=False,\n",
      "2023-09-07 09:41:24 - deepspeed=None,\n",
      "2023-09-07 09:41:24 - debug=[],\n",
      "2023-09-07 09:41:24 - generation_config=None,\n",
      "2023-09-07 09:41:24 - full_determinism=False,\n",
      "2023-09-07 09:41:24 - fsdp_transformer_layer_cls_to_wrap=None,\n",
      "2023-09-07 09:41:24 - fsdp_min_num_params=0,\n",
      "2023-09-07 09:41:24 - fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "2023-09-07 09:41:24 - fsdp=[],\n",
      "2023-09-07 09:41:24 - fp16_opt_level=O1,\n",
      "2023-09-07 09:41:24 - fp16_full_eval=False,\n",
      "2023-09-07 09:41:24 - fp16_backend=auto,\n",
      "2023-09-07 09:41:24 - fp16=True,\n",
      "2023-09-07 09:41:24 - half_precision_backend=auto,\n",
      "2023-09-07 09:41:24 - group_by_length=False,\n",
      "2023-09-07 09:41:24 - greater_is_better=None,\n",
      "2023-09-07 09:41:24 - gradient_checkpointing=True,\n",
      "2023-09-07 09:41:24 - gradient_accumulation_steps=8,\n",
      "2023-09-07 09:41:24 - generation_num_beams=None,\n",
      "2023-09-07 09:41:24 - generation_max_length=225,\n",
      "2023-09-07 09:41:24 - learning_rate=1e-05,\n",
      "2023-09-07 09:41:24 - label_smoothing_factor=0.0,\n",
      "2023-09-07 09:41:24 - label_names=None,\n",
      "2023-09-07 09:41:24 - jit_mode_eval=False,\n",
      "2023-09-07 09:41:24 - include_inputs_for_metrics=False,\n",
      "2023-09-07 09:41:24 - ignore_data_skip=False,\n",
      "2023-09-07 09:41:24 - hub_token=<HUB_TOKEN>,\n",
      "2023-09-07 09:41:24 - hub_strategy=every_save,\n",
      "2023-09-07 09:41:24 - hub_private_repo=False,\n",
      "2023-09-07 09:41:24 - hub_model_id=None,\n",
      "2023-09-07 09:41:24 - logging_dir=/mnt/output/runs/Sep07_09-41-24_c75c86adb29f,\n",
      "2023-09-07 09:41:24 - log_on_each_node=True,\n",
      "2023-09-07 09:41:24 - log_level_replica=warning,\n",
      "2023-09-07 09:41:24 - log_level=passive,\n",
      "2023-09-07 09:41:24 - local_rank=0,\n",
      "2023-09-07 09:41:24 - load_best_model_at_end=False,\n",
      "2023-09-07 09:41:24 - length_column_name=input_length,\n",
      "2023-09-07 09:41:24 - no_cuda=False,\n",
      "2023-09-07 09:41:24 - mp_parameters=,\n",
      "2023-09-07 09:41:24 - metric_for_best_model=None,\n",
      "2023-09-07 09:41:24 - max_steps=1000,\n",
      "2023-09-07 09:41:24 - max_grad_norm=1.0,\n",
      "2023-09-07 09:41:24 - lr_scheduler_type=linear,\n",
      "2023-09-07 09:41:24 - logging_strategy=steps,\n",
      "2023-09-07 09:41:24 - logging_steps=25,\n",
      "2023-09-07 09:41:24 - logging_nan_inf_filter=True,\n",
      "2023-09-07 09:41:24 - logging_first_step=False,\n",
      "2023-09-07 09:41:24 - per_device_eval_batch_size=8,\n",
      "2023-09-07 09:41:24 - past_index=-1,\n",
      "2023-09-07 09:41:24 - overwrite_output_dir=True,\n",
      "2023-09-07 09:41:24 - output_dir=/mnt/output,\n",
      "2023-09-07 09:41:24 - optim_args=None,\n",
      "2023-09-07 09:41:24 - optim=adamw_hf,\n",
      "2023-09-07 09:41:24 - num_train_epochs=3.0,\n",
      "2023-09-07 09:41:24 - report_to=['mlflow', 'tensorboard'],\n",
      "2023-09-07 09:41:24 - remove_unused_columns=True,\n",
      "2023-09-07 09:41:24 - ray_scope=last,\n",
      "2023-09-07 09:41:24 - push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "2023-09-07 09:41:24 - push_to_hub_organization=None,\n",
      "2023-09-07 09:41:24 - push_to_hub_model_id=None,\n",
      "2023-09-07 09:41:24 - push_to_hub=False,\n",
      "2023-09-07 09:41:24 - prediction_loss_only=False,\n",
      "2023-09-07 09:41:24 - predict_with_generate=True,\n",
      "2023-09-07 09:41:24 - per_device_train_batch_size=2,\n",
      "2023-09-07 09:41:24 - seed=42,\n",
      "2023-09-07 09:41:24 - save_total_limit=None,\n",
      "2023-09-07 09:41:24 - save_strategy=steps,\n",
      "2023-09-07 09:41:24 - save_steps=50,\n",
      "2023-09-07 09:41:24 - save_safetensors=False,\n",
      "2023-09-07 09:41:24 - save_on_each_node=False,\n",
      "2023-09-07 09:41:24 - run_name=/mnt/output,\n",
      "2023-09-07 09:41:24 - resume_from_checkpoint=None,\n",
      "2023-09-07 09:41:24 - torchdynamo=None,\n",
      "2023-09-07 09:41:24 - torch_compile_mode=None,\n",
      "2023-09-07 09:41:24 - torch_compile_backend=None,\n",
      "2023-09-07 09:41:24 - torch_compile=False,\n",
      "2023-09-07 09:41:24 - tf32=None,\n",
      "2023-09-07 09:41:24 - sortish_sampler=False,\n",
      "2023-09-07 09:41:24 - skip_memory_metrics=True,\n",
      "2023-09-07 09:41:24 - sharded_ddp=[],\n",
      "2023-09-07 09:41:24 - weight_decay=0.0,\n",
      "2023-09-07 09:41:24 - warmup_steps=200,\n",
      "2023-09-07 09:41:24 - warmup_ratio=0.0,\n",
      "2023-09-07 09:41:24 - use_mps_device=False,\n",
      "2023-09-07 09:41:24 - use_legacy_prediction_loop=False,\n",
      "2023-09-07 09:41:24 - use_ipex=False,\n",
      "2023-09-07 09:41:24 - tpu_num_cores=None,\n",
      "2023-09-07 09:41:24 - tpu_metrics_debug=False,\n",
      "2023-09-07 09:41:24 - 09/07/2023 09:41:24 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "2023-09-07 09:41:24 - )\n",
      "2023-09-07 09:41:24 - xpu_backend=None,\n",
      "2023-09-07 09:41:25 - Downloading and preparing dataset None/None (download: 120.09 MiB, generated: 121.04 MiB, post-processed: Unknown size, total: 241.14 MiB) to /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "2023-09-07 09:41:28 - Dataset parquet downloaded and prepared to /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "2023-09-07 09:41:28 - 09/07/2023 09:41:28 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-07 09:41:29 - 09/07/2023 09:41:29 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-07 09:41:29 - 09/07/2023 09:41:29 - WARNING - datasets.builder - Found cached dataset parquet (/home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "2023-09-07 09:41:53 - If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
      "2023-09-07 09:41:53 - [INFO|modeling_utils.py:3303] 2023-09-07 09:41:53,312 >> All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at openai/whisper-medium.\n",
      "2023-09-07 09:41:53 - \n",
      "2023-09-07 09:41:53 - [INFO|modeling_utils.py:3295] 2023-09-07 09:41:53,312 >> All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
      "Downloading (â€¦)neration_config.json: 100% 3.69k/3.69k [00:00<00:00, 1.92MB/s]\n",
      "2023-09-07 09:41:53 - [INFO|configuration_utils.py:539] 2023-09-07 09:41:53,476 >> loading configuration file generation_config.json from cache at /home/datascience/.cache/huggingface/hub/models--openai--whisper-medium/snapshots/edffa066cd39a0c5c58927735430ab5d630456a8/generation_config.json\n",
      "2023-09-07 09:41:53 -       15\n",
      "2023-09-07 09:41:53 -       13,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -   \"alignment_heads\": [\n",
      "2023-09-07 09:41:53 - [INFO|configuration_utils.py:577] 2023-09-07 09:41:53,476 >> Generate config GenerationConfig {\n",
      "2023-09-07 09:41:53 -       15,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       4\n",
      "2023-09-07 09:41:53 -       15,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       16,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       15\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       0\n",
      "2023-09-07 09:41:53 -       20,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       1\n",
      "2023-09-07 09:41:53 -     220,\n",
      "2023-09-07 09:41:53 -   \"begin_suppress_tokens\": [\n",
      "2023-09-07 09:41:53 -   ],\n",
      "2023-09-07 09:41:53 -     ]\n",
      "2023-09-07 09:41:53 -       4\n",
      "2023-09-07 09:41:53 -       23,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -   \"eos_token_id\": 50257,\n",
      "2023-09-07 09:41:53 -   \"decoder_start_token_id\": 50258,\n",
      "2023-09-07 09:41:53 -   \"bos_token_id\": 50257,\n",
      "2023-09-07 09:41:53 -   ],\n",
      "2023-09-07 09:41:53 -     50257\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -     ],\n",
      "2023-09-07 09:41:53 -       null\n",
      "2023-09-07 09:41:53 -       1,\n",
      "2023-09-07 09:41:53 -     [\n",
      "2023-09-07 09:41:53 -   \"forced_decoder_ids\": [\n",
      "2023-09-07 09:41:53 -   \"is_multilingual\": true,\n",
      "2023-09-07 09:41:53 -   ],\n",
      "2023-09-07 09:41:53 -     ]\n",
      "2023-09-07 09:41:53 -       50359\n",
      "2023-09-07 09:41:53 -       2,\n",
      "2023-09-07 09:41:53 -     \"<|as|>\": 50350,\n",
      "2023-09-07 09:41:53 -     \"<|ar|>\": 50272,\n",
      "2023-09-07 09:41:53 -     \"<|am|>\": 50334,\n",
      "2023-09-07 09:41:53 -     \"<|af|>\": 50327,\n",
      "2023-09-07 09:41:53 -   \"lang_to_id\": {\n",
      "2023-09-07 09:41:53 -     \"<|bs|>\": 50315,\n",
      "2023-09-07 09:41:53 -     \"<|br|>\": 50309,\n",
      "2023-09-07 09:41:53 -     \"<|bo|>\": 50347,\n",
      "2023-09-07 09:41:53 -     \"<|bn|>\": 50302,\n",
      "2023-09-07 09:41:53 -     \"<|bg|>\": 50292,\n",
      "2023-09-07 09:41:53 -     \"<|be|>\": 50330,\n",
      "2023-09-07 09:41:53 -     \"<|ba|>\": 50355,\n",
      "2023-09-07 09:41:53 -     \"<|az|>\": 50304,\n",
      "2023-09-07 09:41:53 -     \"<|en|>\": 50259,\n",
      "2023-09-07 09:41:53 -     \"<|el|>\": 50281,\n",
      "2023-09-07 09:41:53 -     \"<|de|>\": 50261,\n",
      "2023-09-07 09:41:53 -     \"<|da|>\": 50285,\n",
      "2023-09-07 09:41:53 -     \"<|cy|>\": 50297,\n",
      "2023-09-07 09:41:53 -     \"<|cs|>\": 50283,\n",
      "2023-09-07 09:41:53 -     \"<|ca|>\": 50270,\n",
      "2023-09-07 09:41:53 -     \"<|fr|>\": 50265,\n",
      "2023-09-07 09:41:53 -     \"<|fo|>\": 50338,\n",
      "2023-09-07 09:41:53 -     \"<|fi|>\": 50277,\n",
      "2023-09-07 09:41:53 -     \"<|fa|>\": 50300,\n",
      "2023-09-07 09:41:53 -     \"<|eu|>\": 50310,\n",
      "2023-09-07 09:41:53 -     \"<|et|>\": 50307,\n",
      "2023-09-07 09:41:53 -     \"<|es|>\": 50262,\n",
      "2023-09-07 09:41:53 -     \"<|ht|>\": 50339,\n",
      "2023-09-07 09:41:53 -     \"<|hr|>\": 50291,\n",
      "2023-09-07 09:41:53 -     \"<|hi|>\": 50276,\n",
      "2023-09-07 09:41:53 -     \"<|he|>\": 50279,\n",
      "2023-09-07 09:41:53 -     \"<|ha|>\": 50354,\n",
      "2023-09-07 09:41:53 -     \"<|haw|>\": 50352,\n",
      "2023-09-07 09:41:53 -     \"<|gu|>\": 50333,\n",
      "2023-09-07 09:41:53 -     \"<|gl|>\": 50319,\n",
      "2023-09-07 09:41:53 -     \"<|jw|>\": 50356,\n",
      "2023-09-07 09:41:53 -     \"<|ja|>\": 50266,\n",
      "2023-09-07 09:41:53 -     \"<|it|>\": 50274,\n",
      "2023-09-07 09:41:53 -     \"<|is|>\": 50311,\n",
      "2023-09-07 09:41:53 -     \"<|id|>\": 50275,\n",
      "2023-09-07 09:41:53 -     \"<|hy|>\": 50312,\n",
      "2023-09-07 09:41:53 -     \"<|hu|>\": 50286,\n",
      "2023-09-07 09:41:53 -     \"<|ko|>\": 50264,\n",
      "2023-09-07 09:41:53 -     \"<|kn|>\": 50306,\n",
      "2023-09-07 09:41:53 -     \"<|km|>\": 50323,\n",
      "2023-09-07 09:41:53 -     \"<|kk|>\": 50316,\n",
      "2023-09-07 09:41:53 -     \"<|ka|>\": 50329,\n",
      "2023-09-07 09:41:53 -     \"<|mi|>\": 50295,\n",
      "2023-09-07 09:41:53 -     \"<|mg|>\": 50349,\n",
      "2023-09-07 09:41:53 -     \"<|lv|>\": 50301,\n",
      "2023-09-07 09:41:53 -     \"<|lt|>\": 50293,\n",
      "2023-09-07 09:41:53 -     \"<|lo|>\": 50336,\n",
      "2023-09-07 09:41:53 -     \"<|ln|>\": 50353,\n",
      "2023-09-07 09:41:53 -     \"<|lb|>\": 50345,\n",
      "2023-09-07 09:41:53 -     \"<|la|>\": 50294,\n",
      "2023-09-07 09:41:53 -     \"<|my|>\": 50346,\n",
      "2023-09-07 09:41:53 -     \"<|mt|>\": 50343,\n",
      "2023-09-07 09:41:53 -     \"<|ms|>\": 50282,\n",
      "2023-09-07 09:41:53 -     \"<|mr|>\": 50320,\n",
      "2023-09-07 09:41:53 -     \"<|mn|>\": 50314,\n",
      "2023-09-07 09:41:53 -     \"<|ml|>\": 50296,\n",
      "2023-09-07 09:41:53 -     \"<|mk|>\": 50308,\n",
      "2023-09-07 09:41:53 -     \"<|ps|>\": 50340,\n",
      "2023-09-07 09:41:53 -     \"<|pl|>\": 50269,\n",
      "2023-09-07 09:41:53 -     \"<|pa|>\": 50321,\n",
      "2023-09-07 09:41:53 -     \"<|oc|>\": 50328,\n",
      "2023-09-07 09:41:53 -     \"<|no|>\": 50288,\n",
      "2023-09-07 09:41:53 -     \"<|nn|>\": 50342,\n",
      "2023-09-07 09:41:53 -     \"<|nl|>\": 50271,\n",
      "2023-09-07 09:41:53 -     \"<|ne|>\": 50313,\n",
      "2023-09-07 09:41:53 -     \"<|sk|>\": 50298,\n",
      "2023-09-07 09:41:53 -     \"<|si|>\": 50322,\n",
      "2023-09-07 09:41:53 -     \"<|sd|>\": 50332,\n",
      "2023-09-07 09:41:53 -     \"<|sa|>\": 50344,\n",
      "2023-09-07 09:41:53 -     \"<|ru|>\": 50263,\n",
      "2023-09-07 09:41:53 -     \"<|ro|>\": 50284,\n",
      "2023-09-07 09:41:53 -     \"<|pt|>\": 50267,\n",
      "2023-09-07 09:41:53 -     \"<|sv|>\": 50273,\n",
      "2023-09-07 09:41:53 -     \"<|su|>\": 50357,\n",
      "2023-09-07 09:41:53 -     \"<|sr|>\": 50303,\n",
      "2023-09-07 09:41:53 -     \"<|sq|>\": 50317,\n",
      "2023-09-07 09:41:53 -     \"<|so|>\": 50326,\n",
      "2023-09-07 09:41:53 -     \"<|sn|>\": 50324,\n",
      "2023-09-07 09:41:53 -     \"<|sl|>\": 50305,\n",
      "2023-09-07 09:41:53 -     \"<|tr|>\": 50268,\n",
      "2023-09-07 09:41:53 -     \"<|tl|>\": 50348,\n",
      "2023-09-07 09:41:53 -     \"<|tk|>\": 50341,\n",
      "2023-09-07 09:41:53 -     \"<|th|>\": 50289,\n",
      "2023-09-07 09:41:53 -     \"<|tg|>\": 50331,\n",
      "2023-09-07 09:41:53 -     \"<|te|>\": 50299,\n",
      "2023-09-07 09:41:53 -     \"<|ta|>\": 50287,\n",
      "2023-09-07 09:41:53 -     \"<|sw|>\": 50318,\n",
      "2023-09-07 09:41:53 -     \"<|yo|>\": 50325,\n",
      "2023-09-07 09:41:53 -     \"<|yi|>\": 50335,\n",
      "2023-09-07 09:41:53 -     \"<|vi|>\": 50278,\n",
      "2023-09-07 09:41:53 -     \"<|uz|>\": 50337,\n",
      "2023-09-07 09:41:53 -     \"<|ur|>\": 50290,\n",
      "2023-09-07 09:41:53 -     \"<|uk|>\": 50280,\n",
      "2023-09-07 09:41:53 -     \"<|tt|>\": 50351,\n",
      "2023-09-07 09:41:53 -   \"suppress_tokens\": [\n",
      "2023-09-07 09:41:53 -   \"pad_token_id\": 50257,\n",
      "2023-09-07 09:41:53 -   \"no_timestamps_token_id\": 50363,\n",
      "2023-09-07 09:41:53 -   \"max_length\": 448,\n",
      "2023-09-07 09:41:53 -   \"max_initial_timestamp_index\": 1,\n",
      "2023-09-07 09:41:53 -   },\n",
      "2023-09-07 09:41:53 -     \"<|zh|>\": 50260\n",
      "2023-09-07 09:41:53 -     25,\n",
      "2023-09-07 09:41:53 -     14,\n",
      "2023-09-07 09:41:53 -     10,\n",
      "2023-09-07 09:41:53 -     9,\n",
      "2023-09-07 09:41:53 -     8,\n",
      "2023-09-07 09:41:53 -     7,\n",
      "2023-09-07 09:41:53 -     2,\n",
      "2023-09-07 09:41:53 -     1,\n",
      "2023-09-07 09:41:53 -     59,\n",
      "2023-09-07 09:41:53 -     58,\n",
      "2023-09-07 09:41:53 -     31,\n",
      "2023-09-07 09:41:53 -     29,\n",
      "2023-09-07 09:41:53 -     28,\n",
      "2023-09-07 09:41:53 -     27,\n",
      "2023-09-07 09:41:53 -     26,\n",
      "2023-09-07 09:41:53 -     90,\n",
      "2023-09-07 09:41:53 -     63,\n",
      "2023-09-07 09:41:53 -     62,\n",
      "2023-09-07 09:41:53 -     61,\n",
      "2023-09-07 09:41:53 -     60,\n",
      "2023-09-07 09:41:53 -     873,\n",
      "2023-09-07 09:41:53 -     542,\n",
      "2023-09-07 09:41:53 -     522,\n",
      "2023-09-07 09:41:53 -     503,\n",
      "2023-09-07 09:41:53 -     359,\n",
      "2023-09-07 09:41:53 -     93,\n",
      "2023-09-07 09:41:53 -     92,\n",
      "2023-09-07 09:41:53 -     91,\n",
      "2023-09-07 09:41:53 -     1853,\n",
      "2023-09-07 09:41:53 -     1350,\n",
      "2023-09-07 09:41:53 -     931,\n",
      "2023-09-07 09:41:53 -     922,\n",
      "2023-09-07 09:41:53 -     918,\n",
      "2023-09-07 09:41:53 -     902,\n",
      "2023-09-07 09:41:53 -     893,\n",
      "2023-09-07 09:41:53 -     3536,\n",
      "2023-09-07 09:41:53 -     3268,\n",
      "2023-09-07 09:41:53 -     3253,\n",
      "2023-09-07 09:41:53 -     3246,\n",
      "2023-09-07 09:41:53 -     2627,\n",
      "2023-09-07 09:41:53 -     2460,\n",
      "2023-09-07 09:41:53 -     1982,\n",
      "2023-09-07 09:41:53 -     9061,\n",
      "2023-09-07 09:41:53 -     7273,\n",
      "2023-09-07 09:41:53 -     6647,\n",
      "2023-09-07 09:41:53 -     6585,\n",
      "2023-09-07 09:41:53 -     4667,\n",
      "2023-09-07 09:41:53 -     4183,\n",
      "2023-09-07 09:41:53 -     3961,\n",
      "2023-09-07 09:41:53 -     3846,\n",
      "2023-09-07 09:41:53 -     12033,\n",
      "2023-09-07 09:41:53 -     11938,\n",
      "2023-09-07 09:41:53 -     10929,\n",
      "2023-09-07 09:41:53 -     10428,\n",
      "2023-09-07 09:41:53 -     9383,\n",
      "2023-09-07 09:41:53 -     18362,\n",
      "2023-09-07 09:41:53 -     16604,\n",
      "2023-09-07 09:41:53 -     16553,\n",
      "2023-09-07 09:41:53 -     15618,\n",
      "2023-09-07 09:41:53 -     15265,\n",
      "2023-09-07 09:41:53 -     14635,\n",
      "2023-09-07 09:41:53 -     14157,\n",
      "2023-09-07 09:41:53 -     13793,\n",
      "2023-09-07 09:41:53 -     12562,\n",
      "2023-09-07 09:41:53 -     12331,\n",
      "2023-09-07 09:41:53 -     28279,\n",
      "2023-09-07 09:41:53 -     26435,\n",
      "2023-09-07 09:41:53 -     26161,\n",
      "2023-09-07 09:41:53 -     26130,\n",
      "2023-09-07 09:41:53 -     22520,\n",
      "2023-09-07 09:41:53 -     21675,\n",
      "2023-09-07 09:41:53 -     20075,\n",
      "2023-09-07 09:41:53 -     18956,\n",
      "2023-09-07 09:41:53 -     47425,\n",
      "2023-09-07 09:41:53 -     42863,\n",
      "2023-09-07 09:41:53 -     36865,\n",
      "2023-09-07 09:41:53 -     32470,\n",
      "2023-09-07 09:41:53 -     32302,\n",
      "2023-09-07 09:41:53 -     31650,\n",
      "2023-09-07 09:41:53 -     29464,\n",
      "2023-09-07 09:41:53 -     50361,\n",
      "2023-09-07 09:41:53 -     50360,\n",
      "2023-09-07 09:41:53 -     50359,\n",
      "2023-09-07 09:41:53 -     50358,\n",
      "2023-09-07 09:41:53 -     50258,\n",
      "2023-09-07 09:41:53 -     50254,\n",
      "2023-09-07 09:41:53 -     49870,\n",
      "2023-09-07 09:41:53 -   \"transformers_version\": \"4.30.2\"\n",
      "2023-09-07 09:41:53 -   },\n",
      "2023-09-07 09:41:53 -     \"translate\": 50358\n",
      "2023-09-07 09:41:53 -     \"transcribe\": 50359,\n",
      "2023-09-07 09:41:53 -   \"task_to_id\": {\n",
      "2023-09-07 09:41:53 -   ],\n",
      "2023-09-07 09:41:53 -     50362\n",
      "2023-09-07 09:41:53 - \n",
      "2023-09-07 09:41:53 - }\n",
      "Downloading builder script: 100% 4.49k/4.49k [00:00<00:00, 6.99MB/s]  \n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:2194] 2023-09-07 09:42:16,840 >> tokenizer config file saved in /mnt/output/tokenizer_config.json\n",
      "2023-09-07 09:42:16 - [INFO|feature_extraction_utils.py:377] 2023-09-07 09:42:16,840 >> Feature extractor saved in /mnt/output/preprocessor_config.json\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:2201] 2023-09-07 09:42:16,840 >> Special tokens file saved in /mnt/output/special_tokens_map.json\n",
      "Downloading builder script: 100% 4.49k/4.49k [00:00<00:00, 4.43MB/s]\n",
      "2023-09-07 09:42:16 - [INFO|configuration_utils.py:458] 2023-09-07 09:42:16,942 >> Configuration saved in /mnt/output/config.json\n",
      "2023-09-07 09:42:16 - [INFO|image_processing_utils.py:307] 2023-09-07 09:42:16,961 >> loading configuration file /mnt/output/preprocessor_config.json\n",
      "2023-09-07 09:42:16 -   \"chunk_length\": 30,\n",
      "2023-09-07 09:42:16 - [INFO|feature_extraction_utils.py:519] 2023-09-07 09:42:16,969 >> Feature extractor WhisperFeatureExtractor {\n",
      "2023-09-07 09:42:16 - [INFO|feature_extraction_utils.py:475] 2023-09-07 09:42:16,968 >> loading configuration file /mnt/output/preprocessor_config.json\n",
      "2023-09-07 09:42:16 -   \"nb_max_frames\": 3000,\n",
      "2023-09-07 09:42:16 -   \"n_samples\": 480000,\n",
      "2023-09-07 09:42:16 -   \"n_fft\": 400,\n",
      "2023-09-07 09:42:16 -   \"hop_length\": 160,\n",
      "2023-09-07 09:42:16 -   \"feature_size\": 80,\n",
      "2023-09-07 09:42:16 -   \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
      "2023-09-07 09:42:16 -   \"return_attention_mask\": false,\n",
      "2023-09-07 09:42:16 -   \"processor_class\": \"WhisperProcessor\",\n",
      "2023-09-07 09:42:16 -   \"padding_value\": 0.0,\n",
      "2023-09-07 09:42:16 -   \"padding_side\": \"right\",\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file added_tokens.json\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file normalizer.json\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file merges.txt\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file tokenizer.json\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file vocab.json\n",
      "2023-09-07 09:42:16 - \n",
      "2023-09-07 09:42:16 - }\n",
      "2023-09-07 09:42:16 -   \"sampling_rate\": 16000\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file tokenizer_config.json\n",
      "2023-09-07 09:42:16 - [INFO|tokenization_utils_base.py:1821] 2023-09-07 09:42:16,969 >> loading file special_tokens_map.json\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|ru|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|es|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|de|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|zh|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|en|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|startoftranscript|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|fr|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|ko|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|pl|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|tr|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|pt|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|ja|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|fi|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|hi|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|id|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|it|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|sv|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|ar|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|nl|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,027 >> Adding <|ca|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ro|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|cs|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ms|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|el|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|uk|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|he|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|vi|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|th|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|no|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ta|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|hu|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|da|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|cy|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ml|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|mi|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|la|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|lt|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|bg|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|hr|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ur|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|bn|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|lv|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|fa|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|te|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|sk|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|br|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|mk|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|et|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|kn|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|sl|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|az|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|sr|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|mn|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|ne|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|hy|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|is|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,028 >> Adding <|eu|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|si|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|pa|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|mr|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|gl|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|sw|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|sq|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|kk|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|bs|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|ka|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|oc|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|af|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|so|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|yo|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|sn|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|km|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|am|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|gu|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|sd|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|tg|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|be|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|tk|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|ps|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|ht|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|fo|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|uz|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|lo|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|yi|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|my|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|lb|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|sa|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|mt|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|nn|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|ln|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|haw|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|tt|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|as|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|mg|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|tl|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,029 >> Adding <|bo|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|startoflm|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|transcribe|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|translate|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|su|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|jw|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|ba|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|ha|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|notimestamps|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|nocaptions|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|tokenization_utils.py:426] 2023-09-07 09:42:17,030 >> Adding <|startofprev|> to the vocabulary\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:577] 2023-09-07 09:42:17,406 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:776] 2023-09-07 09:42:17,566 >> The following columns in the training set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1791] 2023-09-07 09:42:17,644 >>   Gradient Accumulation steps = 8\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1790] 2023-09-07 09:42:17,644 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1789] 2023-09-07 09:42:17,644 >>   Instantaneous batch size per device = 2\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1788] 2023-09-07 09:42:17,644 >>   Num Epochs = 67\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1787] 2023-09-07 09:42:17,644 >>   Num examples = 504\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1786] 2023-09-07 09:42:17,644 >> ***** Running training *****\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1792] 2023-09-07 09:42:17,644 >>   Total optimization steps = 1,000\n",
      "2023-09-07 09:42:17 - [INFO|trainer.py:1793] 2023-09-07 09:42:17,647 >>   Number of trainable parameters = 763,857,920\n",
      "  0% 0/1000 [00:00<?, ?it/s][WARNING|logging.py:295] 2023-09-07 09:42:19,077 >> `use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
      "2023-09-07 09:42:19 - [WARNING|logging.py:295] 2023-09-07 09:42:19,320 >> `use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
      "2023-09-07 09:42:16 - 09/07/2023 09:42:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-284f2078bb933bb9.arrow\n",
      "2023-09-07 09:42:16 - 09/07/2023 09:42:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-275d64deb6b64785.arrow\n",
      "2023-09-07 09:42:16 - 09/07/2023 09:42:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-a9ad010831b354da.arrow\n",
      "2023-09-07 09:42:16 - 09/07/2023 09:42:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/datascience/.cache/huggingface/datasets/luigisaetta___parquet/luigisaetta--atco2-e21010af6311e730/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-765a093aad63ba95.arrow\n",
      "2023-09-07 09:42:17 -   warnings.warn(\n",
      "2023-09-07 09:42:17 - 09/07/2023 09:42:17 - WARNING - py.warnings - /home/datascience/conda/whisper_env_v1_0/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "2023-09-07 09:42:17 - \n",
      "2023-09-07 09:42:17 - \n",
      "2023-09-07 09:42:17 -   warnings.warn(\n",
      "2023-09-07 09:42:17 - 09/07/2023 09:42:17 - WARNING - py.warnings - /home/datascience/conda/whisper_env_v1_0/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "2023-09-07 09:42:17 - \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-09-07 09:42:17 - \t- Avoid using `tokenizers` before the fork if possible\n",
      "2023-09-07 09:42:17 - To disable this warning, you can either:\n",
      "2023-09-07 09:42:17 - huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "2023-09-07 09:42:17 - \t- Avoid using `tokenizers` before the fork if possible\n",
      "2023-09-07 09:42:17 - To disable this warning, you can either:\n",
      "2023-09-07 09:42:17 - huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "2023-09-07 09:42:17 - \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2023-09-07 09:45:11 - {'loss': 2.5616, 'learning_rate': 1.2000000000000002e-06, 'epoch': 1.59}\n",
      " 75% 3/4 [00:14<00:05,  5.21s/it]\u001b[A\n",
      "                                       \n",
      "100% 4/4 [00:22<00:00,  6.01s/it]\u001b[A\n",
      "2023-09-07 09:48:34 - [INFO|configuration_utils.py:458] 2023-09-07 09:48:34,934 >> Configuration saved in /mnt/output/checkpoint-50/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 09:48:34,933 >> Saving model checkpoint to /mnt/output/checkpoint-50\n",
      "  5% 50/1000 [06:17<1:49:47,  6.93s/it]\n",
      "2023-09-07 09:48:34 - [INFO|configuration_utils.py:364] 2023-09-07 09:48:34,935 >> Configuration saved in /mnt/output/checkpoint-50/generation_config.json\n",
      "2023-09-07 09:48:37 - [INFO|modeling_utils.py:1853] 2023-09-07 09:48:37,601 >> Model weights saved in /mnt/output/checkpoint-50/pytorch_model.bin\n",
      "2023-09-07 09:48:37 - [INFO|feature_extraction_utils.py:377] 2023-09-07 09:48:37,602 >> Feature extractor saved in /mnt/output/checkpoint-50/preprocessor_config.json\n",
      "2023-09-07 09:48:04 - {'loss': 1.3051, 'learning_rate': 2.4000000000000003e-06, 'epoch': 3.17}\n",
      "  5% 50/1000 [05:46<1:49:47,  6.93s/it][INFO|trainer.py:776] 2023-09-07 09:48:04,392 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 09:48:04 - [INFO|trainer.py:3200] 2023-09-07 09:48:04,394 >> ***** Running Evaluation *****\n",
      "2023-09-07 09:48:04 - [INFO|trainer.py:3205] 2023-09-07 09:48:04,394 >>   Batch size = 8\n",
      "2023-09-07 09:48:04 - [INFO|trainer.py:3202] 2023-09-07 09:48:04,394 >>   Num examples = 55\n",
      "2023-09-07 09:48:12 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:07<00:07,  3.67s/it]\u001b[A\n",
      "2023-09-07 09:48:34 - {'eval_loss': 0.9045917391777039, 'eval_wer': 0.5461465271170314, 'eval_runtime': 30.5357, 'eval_samples_per_second': 1.801, 'eval_steps_per_second': 0.131, 'epoch': 3.17}\n",
      "2023-09-07 09:51:35 - {'loss': 0.5214, 'learning_rate': 3.65e-06, 'epoch': 4.76}\n",
      "2023-09-07 09:54:28 - {'loss': 0.2137, 'learning_rate': 4.9000000000000005e-06, 'epoch': 6.35}\n",
      "2023-09-07 09:54:57 - {'eval_loss': 0.5140445232391357, 'eval_wer': 0.28068506184586106, 'eval_runtime': 29.3169, 'eval_samples_per_second': 1.876, 'eval_steps_per_second': 0.136, 'epoch': 6.35}\n",
      "2023-09-07 09:55:00 - [INFO|modeling_utils.py:1853] 2023-09-07 09:55:00,416 >> Model weights saved in /mnt/output/checkpoint-100/pytorch_model.bin\n",
      "2023-09-07 09:55:00 - [INFO|feature_extraction_utils.py:377] 2023-09-07 09:55:00,418 >> Feature extractor saved in /mnt/output/checkpoint-100/preprocessor_config.json\n",
      " 10% 100/1000 [12:10<1:43:29,  6.90s/it][INFO|trainer.py:776] 2023-09-07 09:54:28,389 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 09:54:28 - [INFO|trainer.py:3205] 2023-09-07 09:54:28,391 >>   Batch size = 8\n",
      "2023-09-07 09:54:28 - [INFO|trainer.py:3202] 2023-09-07 09:54:28,391 >>   Num examples = 55\n",
      "2023-09-07 09:54:28 - [INFO|trainer.py:3200] 2023-09-07 09:54:28,390 >> ***** Running Evaluation *****\n",
      "2023-09-07 09:54:35 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:07<00:07,  3.68s/it]\u001b[A\n",
      " 75% 3/4 [00:14<00:05,  5.16s/it]\u001b[A\n",
      " 10% 100/1000 [12:39<1:43:29,  6.90s/it]\n",
      "                                        \n",
      "100% 4/4 [00:21<00:00,  5.98s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 09:54:57,758 >> Saving model checkpoint to /mnt/output/checkpoint-100\n",
      "2023-09-07 09:54:57 - [INFO|configuration_utils.py:458] 2023-09-07 09:54:57,759 >> Configuration saved in /mnt/output/checkpoint-100/config.json\n",
      "2023-09-07 09:54:57 - [INFO|configuration_utils.py:364] 2023-09-07 09:54:57,760 >> Configuration saved in /mnt/output/checkpoint-100/generation_config.json\n",
      "2023-09-07 09:57:58 - {'loss': 0.0798, 'learning_rate': 6.15e-06, 'epoch': 7.94}\n",
      "2023-09-07 10:00:50 - {'loss': 0.0343, 'learning_rate': 7.4e-06, 'epoch': 9.52}\n",
      "2023-09-07 10:01:07 - {'eval_loss': 0.5870081782341003, 'eval_wer': 0.1665080875356803, 'eval_runtime': 17.7408, 'eval_samples_per_second': 3.1, 'eval_steps_per_second': 0.225, 'epoch': 9.52}\n",
      " 15% 150/1000 [18:32<1:37:24,  6.88s/it][INFO|trainer.py:776] 2023-09-07 10:00:50,221 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:00:50 - [INFO|trainer.py:3200] 2023-09-07 10:00:50,223 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:00:50 - [INFO|trainer.py:3205] 2023-09-07 10:00:50,223 >>   Batch size = 8\n",
      "2023-09-07 10:00:50 - [INFO|trainer.py:3202] 2023-09-07 10:00:50,223 >>   Num examples = 55\n",
      "2023-09-07 10:00:54 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.06s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.27s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.64s/it]\u001b[A\n",
      "2023-09-07 10:01:07 - [INFO|configuration_utils.py:458] 2023-09-07 10:01:07,967 >> Configuration saved in /mnt/output/checkpoint-150/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:01:07,966 >> Saving model checkpoint to /mnt/output/checkpoint-150\n",
      " 15% 150/1000 [18:50<1:37:24,  6.88s/it]\n",
      "                                        \n",
      "2023-09-07 10:01:07 - [INFO|configuration_utils.py:364] 2023-09-07 10:01:07,968 >> Configuration saved in /mnt/output/checkpoint-150/generation_config.json\n",
      "2023-09-07 10:01:10 - [INFO|modeling_utils.py:1853] 2023-09-07 10:01:10,608 >> Model weights saved in /mnt/output/checkpoint-150/pytorch_model.bin\n",
      "2023-09-07 10:01:10 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:01:10,609 >> Feature extractor saved in /mnt/output/checkpoint-150/preprocessor_config.json\n",
      "2023-09-07 10:04:07 - {'loss': 0.0236, 'learning_rate': 8.65e-06, 'epoch': 11.11}\n",
      "2023-09-07 10:07:00 - {'loss': 0.0171, 'learning_rate': 9.9e-06, 'epoch': 12.7}\n",
      "2023-09-07 10:07:17 - {'eval_loss': 0.5955320000648499, 'eval_wer': 0.1665080875356803, 'eval_runtime': 17.6582, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 0.227, 'epoch': 12.7}\n",
      " 20% 200/1000 [24:42<1:31:49,  6.89s/it][INFO|trainer.py:776] 2023-09-07 10:07:00,118 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:07:00 - [INFO|trainer.py:3200] 2023-09-07 10:07:00,120 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:07:00 - [INFO|trainer.py:3205] 2023-09-07 10:07:00,120 >>   Batch size = 8\n",
      "2023-09-07 10:07:00 - [INFO|trainer.py:3202] 2023-09-07 10:07:00,120 >>   Num examples = 55\n",
      "2023-09-07 10:07:04 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.05s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.25s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.64s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:07:17,780 >> Saving model checkpoint to /mnt/output/checkpoint-200\n",
      " 20% 200/1000 [24:59<1:31:49,  6.89s/it]\n",
      "2023-09-07 10:07:17 - [INFO|configuration_utils.py:364] 2023-09-07 10:07:17,782 >> Configuration saved in /mnt/output/checkpoint-200/generation_config.json\n",
      "2023-09-07 10:07:17 - [INFO|configuration_utils.py:458] 2023-09-07 10:07:17,781 >> Configuration saved in /mnt/output/checkpoint-200/config.json\n",
      "2023-09-07 10:07:20 - [INFO|modeling_utils.py:1853] 2023-09-07 10:07:20,416 >> Model weights saved in /mnt/output/checkpoint-200/pytorch_model.bin\n",
      "2023-09-07 10:07:20 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:07:20,417 >> Feature extractor saved in /mnt/output/checkpoint-200/preprocessor_config.json\n",
      "2023-09-07 10:10:17 - {'loss': 0.0115, 'learning_rate': 9.7125e-06, 'epoch': 14.29}\n",
      " 25% 250/1000 [30:52<1:26:03,  6.88s/it][INFO|trainer.py:776] 2023-09-07 10:13:10,049 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:13:10 - [INFO|trainer.py:3205] 2023-09-07 10:13:10,051 >>   Batch size = 8\n",
      "2023-09-07 10:13:10 - [INFO|trainer.py:3202] 2023-09-07 10:13:10,051 >>   Num examples = 55\n",
      "2023-09-07 10:13:10 - [INFO|trainer.py:3200] 2023-09-07 10:13:10,051 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:13:14 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.07s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.24s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.63s/it]\u001b[A\n",
      "2023-09-07 10:13:27 - [INFO|configuration_utils.py:458] 2023-09-07 10:13:27,751 >> Configuration saved in /mnt/output/checkpoint-250/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:13:27,750 >> Saving model checkpoint to /mnt/output/checkpoint-250\n",
      " 25% 250/1000 [31:09<1:26:03,  6.88s/it]\n",
      "2023-09-07 10:13:27 - [INFO|configuration_utils.py:364] 2023-09-07 10:13:27,752 >> Configuration saved in /mnt/output/checkpoint-250/generation_config.json\n",
      "2023-09-07 10:13:30 - [INFO|modeling_utils.py:1853] 2023-09-07 10:13:30,386 >> Model weights saved in /mnt/output/checkpoint-250/pytorch_model.bin\n",
      "2023-09-07 10:13:30 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:13:30,387 >> Feature extractor saved in /mnt/output/checkpoint-250/preprocessor_config.json\n",
      "2023-09-07 10:13:10 - {'loss': 0.0107, 'learning_rate': 9.4e-06, 'epoch': 15.87}\n",
      "2023-09-07 10:13:27 - {'eval_loss': 0.5995476245880127, 'eval_wer': 0.15413891531874405, 'eval_runtime': 17.6969, 'eval_samples_per_second': 3.108, 'eval_steps_per_second': 0.226, 'epoch': 15.87}\n",
      "2023-09-07 10:16:27 - {'loss': 0.006, 'learning_rate': 9.0875e-06, 'epoch': 17.46}\n",
      "2023-09-07 10:19:18 - {'loss': 0.0045, 'learning_rate': 8.775e-06, 'epoch': 19.05}\n",
      "2023-09-07 10:19:35 - {'eval_loss': 0.6287272572517395, 'eval_wer': 0.1731684110371075, 'eval_runtime': 17.4001, 'eval_samples_per_second': 3.161, 'eval_steps_per_second': 0.23, 'epoch': 19.05}\n",
      "2023-09-07 10:19:18 - [INFO|trainer.py:3200] 2023-09-07 10:19:18,380 >> ***** Running Evaluation *****\n",
      " 30% 300/1000 [37:00<1:19:58,  6.85s/it][INFO|trainer.py:776] 2023-09-07 10:19:18,378 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:19:18 - [INFO|trainer.py:3205] 2023-09-07 10:19:18,380 >>   Batch size = 8\n",
      "2023-09-07 10:19:18 - [INFO|trainer.py:3202] 2023-09-07 10:19:18,380 >>   Num examples = 55\n",
      "2023-09-07 10:19:22 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.03s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.20s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.57s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:19:35,783 >> Saving model checkpoint to /mnt/output/checkpoint-300\n",
      " 30% 300/1000 [37:17<1:19:58,  6.85s/it]\n",
      "                                        \n",
      "2023-09-07 10:19:35 - [INFO|configuration_utils.py:458] 2023-09-07 10:19:35,784 >> Configuration saved in /mnt/output/checkpoint-300/config.json\n",
      "2023-09-07 10:19:35 - [INFO|configuration_utils.py:364] 2023-09-07 10:19:35,784 >> Configuration saved in /mnt/output/checkpoint-300/generation_config.json\n",
      "2023-09-07 10:19:38 - [INFO|modeling_utils.py:1853] 2023-09-07 10:19:38,459 >> Model weights saved in /mnt/output/checkpoint-300/pytorch_model.bin\n",
      "2023-09-07 10:19:38 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:19:38,460 >> Feature extractor saved in /mnt/output/checkpoint-300/preprocessor_config.json\n",
      "2023-09-07 10:22:35 - {'loss': 0.0037, 'learning_rate': 8.4625e-06, 'epoch': 20.63}\n",
      " 35% 350/1000 [43:09<1:14:21,  6.86s/it][INFO|trainer.py:776] 2023-09-07 10:25:27,211 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:25:27 - [INFO|trainer.py:3200] 2023-09-07 10:25:27,213 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:25:27 - [INFO|trainer.py:3205] 2023-09-07 10:25:27,213 >>   Batch size = 8\n",
      "2023-09-07 10:25:27 - [INFO|trainer.py:3202] 2023-09-07 10:25:27,213 >>   Num examples = 55\n",
      "2023-09-07 10:25:31 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.04s/it]\u001b[A\n",
      " 75% 3/4 [00:09<00:03,  3.27s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.64s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:25:44,885 >> Saving model checkpoint to /mnt/output/checkpoint-350\n",
      " 35% 350/1000 [43:27<1:14:21,  6.86s/it]\n",
      "2023-09-07 10:25:44 - [INFO|configuration_utils.py:364] 2023-09-07 10:25:44,887 >> Configuration saved in /mnt/output/checkpoint-350/generation_config.json\n",
      "2023-09-07 10:25:44 - [INFO|configuration_utils.py:458] 2023-09-07 10:25:44,886 >> Configuration saved in /mnt/output/checkpoint-350/config.json\n",
      "2023-09-07 10:25:47 - [INFO|modeling_utils.py:1853] 2023-09-07 10:25:47,569 >> Model weights saved in /mnt/output/checkpoint-350/pytorch_model.bin\n",
      "2023-09-07 10:25:47 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:25:47,570 >> Feature extractor saved in /mnt/output/checkpoint-350/preprocessor_config.json\n",
      "2023-09-07 10:25:27 - {'loss': 0.0036, 'learning_rate': 8.15e-06, 'epoch': 22.22}\n",
      "2023-09-07 10:25:44 - {'eval_loss': 0.6432343125343323, 'eval_wer': 0.16555661274976213, 'eval_runtime': 17.6699, 'eval_samples_per_second': 3.113, 'eval_steps_per_second': 0.226, 'epoch': 22.22}\n",
      "2023-09-07 10:28:43 - {'loss': 0.0015, 'learning_rate': 7.8375e-06, 'epoch': 23.81}\n",
      "2023-09-07 10:31:34 - {'loss': 0.001, 'learning_rate': 7.525e-06, 'epoch': 25.4}\n",
      "2023-09-07 10:31:51 - {'eval_loss': 0.6878654956817627, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.4914, 'eval_samples_per_second': 3.144, 'eval_steps_per_second': 0.229, 'epoch': 25.4}\n",
      " 40% 400/1000 [49:16<1:08:16,  6.83s/it][INFO|trainer.py:776] 2023-09-07 10:31:34,375 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:31:34 - [INFO|trainer.py:3205] 2023-09-07 10:31:34,377 >>   Batch size = 8\n",
      "2023-09-07 10:31:34 - [INFO|trainer.py:3202] 2023-09-07 10:31:34,377 >>   Num examples = 55\n",
      "2023-09-07 10:31:34 - [INFO|trainer.py:3200] 2023-09-07 10:31:34,377 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:31:38 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.03s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.22s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.60s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:31:51,871 >> Saving model checkpoint to /mnt/output/checkpoint-400\n",
      " 40% 400/1000 [49:33<1:08:16,  6.83s/it]\n",
      "                                        \n",
      "2023-09-07 10:31:51 - [INFO|configuration_utils.py:458] 2023-09-07 10:31:51,872 >> Configuration saved in /mnt/output/checkpoint-400/config.json\n",
      "2023-09-07 10:31:51 - [INFO|configuration_utils.py:364] 2023-09-07 10:31:51,872 >> Configuration saved in /mnt/output/checkpoint-400/generation_config.json\n",
      "2023-09-07 10:31:54 - [INFO|modeling_utils.py:1853] 2023-09-07 10:31:54,547 >> Model weights saved in /mnt/output/checkpoint-400/pytorch_model.bin\n",
      "2023-09-07 10:31:54 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:31:54,548 >> Feature extractor saved in /mnt/output/checkpoint-400/preprocessor_config.json\n",
      "2023-09-07 10:34:51 - {'loss': 0.0005, 'learning_rate': 7.2125e-06, 'epoch': 26.98}\n",
      "2023-09-07 10:37:42 - [INFO|trainer.py:3200] 2023-09-07 10:37:42,269 >> ***** Running Evaluation *****\n",
      " 45% 450/1000 [55:24<1:02:46,  6.85s/it][INFO|trainer.py:776] 2023-09-07 10:37:42,267 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:37:42 - [INFO|trainer.py:3205] 2023-09-07 10:37:42,269 >>   Batch size = 8\n",
      "2023-09-07 10:37:42 - [INFO|trainer.py:3202] 2023-09-07 10:37:42,269 >>   Num examples = 55\n",
      "2023-09-07 10:37:46 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.02s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.22s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.63s/it]\u001b[A\n",
      "2023-09-07 10:37:59 - [INFO|configuration_utils.py:458] 2023-09-07 10:37:59,918 >> Configuration saved in /mnt/output/checkpoint-450/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:37:59,917 >> Saving model checkpoint to /mnt/output/checkpoint-450\n",
      " 45% 450/1000 [55:42<1:02:46,  6.85s/it]\n",
      "2023-09-07 10:37:59 - [INFO|configuration_utils.py:364] 2023-09-07 10:37:59,919 >> Configuration saved in /mnt/output/checkpoint-450/generation_config.json\n",
      "2023-09-07 10:38:02 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:38:02,540 >> Feature extractor saved in /mnt/output/checkpoint-450/preprocessor_config.json\n",
      "2023-09-07 10:38:02 - [INFO|modeling_utils.py:1853] 2023-09-07 10:38:02,539 >> Model weights saved in /mnt/output/checkpoint-450/pytorch_model.bin\n",
      "2023-09-07 10:37:42 - {'loss': 0.0003, 'learning_rate': 6.9e-06, 'epoch': 28.57}\n",
      "2023-09-07 10:37:59 - {'eval_loss': 0.7162216901779175, 'eval_wer': 0.1598477640342531, 'eval_runtime': 17.6454, 'eval_samples_per_second': 3.117, 'eval_steps_per_second': 0.227, 'epoch': 28.57}\n",
      "2023-09-07 10:40:58 - {'loss': 0.0003, 'learning_rate': 6.5875e-06, 'epoch': 30.16}\n",
      "2023-09-07 10:43:50 - {'loss': 0.0002, 'learning_rate': 6.275e-06, 'epoch': 31.75}\n",
      "2023-09-07 10:44:07 - {'eval_loss': 0.722922146320343, 'eval_wer': 0.15794481446241673, 'eval_runtime': 17.6777, 'eval_samples_per_second': 3.111, 'eval_steps_per_second': 0.226, 'epoch': 31.75}\n",
      " 50% 500/1000 [1:01:32<58:09,  6.98s/it][INFO|trainer.py:776] 2023-09-07 10:43:50,257 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:43:50 - [INFO|trainer.py:3200] 2023-09-07 10:43:50,259 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:43:50 - [INFO|trainer.py:3205] 2023-09-07 10:43:50,259 >>   Batch size = 8\n",
      "2023-09-07 10:43:50 - [INFO|trainer.py:3202] 2023-09-07 10:43:50,259 >>   Num examples = 55\n",
      "2023-09-07 10:43:54 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.02s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.22s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.64s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:44:07,939 >> Saving model checkpoint to /mnt/output/checkpoint-500\n",
      " 50% 500/1000 [1:01:50<58:09,  6.98s/it]\n",
      "                                        \n",
      "2023-09-07 10:44:07 - [INFO|configuration_utils.py:364] 2023-09-07 10:44:07,941 >> Configuration saved in /mnt/output/checkpoint-500/generation_config.json\n",
      "2023-09-07 10:44:07 - [INFO|configuration_utils.py:458] 2023-09-07 10:44:07,940 >> Configuration saved in /mnt/output/checkpoint-500/config.json\n",
      "2023-09-07 10:44:10 - [INFO|modeling_utils.py:1853] 2023-09-07 10:44:10,563 >> Model weights saved in /mnt/output/checkpoint-500/pytorch_model.bin\n",
      "2023-09-07 10:44:10 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:44:10,564 >> Feature extractor saved in /mnt/output/checkpoint-500/preprocessor_config.json\n",
      "2023-09-07 10:47:06 - {'loss': 0.0002, 'learning_rate': 5.9625e-06, 'epoch': 33.33}\n",
      " 55% 550/1000 [1:07:39<51:11,  6.83s/it][INFO|trainer.py:776] 2023-09-07 10:49:57,274 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:49:57 - [INFO|trainer.py:3205] 2023-09-07 10:49:57,276 >>   Batch size = 8\n",
      "2023-09-07 10:49:57 - [INFO|trainer.py:3202] 2023-09-07 10:49:57,276 >>   Num examples = 55\n",
      "2023-09-07 10:49:57 - [INFO|trainer.py:3200] 2023-09-07 10:49:57,276 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:50:01 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.04s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.23s/it]\u001b[A\n",
      "100% 4/4 [00:13<00:00,  3.63s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:50:14,935 >> Saving model checkpoint to /mnt/output/checkpoint-550\n",
      " 55% 550/1000 [1:07:57<51:11,  6.83s/it]\n",
      "                                        \n",
      "2023-09-07 10:50:14 - [INFO|configuration_utils.py:458] 2023-09-07 10:50:14,936 >> Configuration saved in /mnt/output/checkpoint-550/config.json\n",
      "2023-09-07 10:50:14 - [INFO|configuration_utils.py:364] 2023-09-07 10:50:14,937 >> Configuration saved in /mnt/output/checkpoint-550/generation_config.json\n",
      "2023-09-07 10:50:17 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:50:17,590 >> Feature extractor saved in /mnt/output/checkpoint-550/preprocessor_config.json\n",
      "2023-09-07 10:50:17 - [INFO|modeling_utils.py:1853] 2023-09-07 10:50:17,589 >> Model weights saved in /mnt/output/checkpoint-550/pytorch_model.bin\n",
      "2023-09-07 10:49:57 - {'loss': 0.0002, 'learning_rate': 5.65e-06, 'epoch': 34.92}\n",
      "2023-09-07 10:50:14 - {'eval_loss': 0.7282211780548096, 'eval_wer': 0.16270218839200762, 'eval_runtime': 17.657, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 0.227, 'epoch': 34.92}\n",
      "2023-09-07 10:53:13 - {'loss': 0.0002, 'learning_rate': 5.3375e-06, 'epoch': 36.51}\n",
      " 60% 600/1000 [1:13:47<45:35,  6.84s/it][INFO|trainer.py:776] 2023-09-07 10:56:05,184 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 10:56:05 - [INFO|trainer.py:3200] 2023-09-07 10:56:05,186 >> ***** Running Evaluation *****\n",
      "2023-09-07 10:56:05 - [INFO|trainer.py:3205] 2023-09-07 10:56:05,186 >>   Batch size = 8\n",
      "2023-09-07 10:56:05 - [INFO|trainer.py:3202] 2023-09-07 10:56:05,186 >>   Num examples = 55\n",
      "2023-09-07 10:56:09 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.02s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.22s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.63s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 10:56:22,831 >> Saving model checkpoint to /mnt/output/checkpoint-600\n",
      " 60% 600/1000 [1:14:04<45:35,  6.84s/it]\n",
      "2023-09-07 10:56:22 - [INFO|configuration_utils.py:458] 2023-09-07 10:56:22,831 >> Configuration saved in /mnt/output/checkpoint-600/config.json\n",
      "2023-09-07 10:56:22 - [INFO|configuration_utils.py:364] 2023-09-07 10:56:22,832 >> Configuration saved in /mnt/output/checkpoint-600/generation_config.json\n",
      "2023-09-07 10:56:25 - [INFO|modeling_utils.py:1853] 2023-09-07 10:56:25,460 >> Model weights saved in /mnt/output/checkpoint-600/pytorch_model.bin\n",
      "2023-09-07 10:56:25 - [INFO|feature_extraction_utils.py:377] 2023-09-07 10:56:25,461 >> Feature extractor saved in /mnt/output/checkpoint-600/preprocessor_config.json\n",
      "2023-09-07 10:56:05 - {'loss': 0.0002, 'learning_rate': 5.025e-06, 'epoch': 38.1}\n",
      "2023-09-07 10:56:22 - {'eval_loss': 0.7321106195449829, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.6421, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 0.227, 'epoch': 38.1}\n",
      "2023-09-07 10:59:21 - {'loss': 0.0001, 'learning_rate': 4.7125e-06, 'epoch': 39.68}\n",
      "2023-09-07 11:02:12 - {'loss': 0.0001, 'learning_rate': 4.4e-06, 'epoch': 41.27}\n",
      "2023-09-07 11:02:30 - {'eval_loss': 0.7359598875045776, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.6373, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 0.227, 'epoch': 41.27}\n",
      " 65% 650/1000 [1:19:54<40:04,  6.87s/it][INFO|trainer.py:776] 2023-09-07 11:02:12,826 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 11:02:12 - [INFO|trainer.py:3205] 2023-09-07 11:02:12,828 >>   Batch size = 8\n",
      "2023-09-07 11:02:12 - [INFO|trainer.py:3202] 2023-09-07 11:02:12,828 >>   Num examples = 55\n",
      "2023-09-07 11:02:12 - [INFO|trainer.py:3200] 2023-09-07 11:02:12,828 >> ***** Running Evaluation *****\n",
      "2023-09-07 11:02:17 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.04s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.22s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.62s/it]\u001b[A\n",
      " 65% 650/1000 [1:20:12<40:04,  6.87s/it]\n",
      "2023-09-07 11:02:30 - [INFO|configuration_utils.py:364] 2023-09-07 11:02:30,469 >> Configuration saved in /mnt/output/checkpoint-650/generation_config.json\n",
      "2023-09-07 11:02:30 - [INFO|configuration_utils.py:458] 2023-09-07 11:02:30,468 >> Configuration saved in /mnt/output/checkpoint-650/config.json\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 11:02:30,468 >> Saving model checkpoint to /mnt/output/checkpoint-650\n",
      "2023-09-07 11:02:33 - [INFO|modeling_utils.py:1853] 2023-09-07 11:02:33,119 >> Model weights saved in /mnt/output/checkpoint-650/pytorch_model.bin\n",
      "2023-09-07 11:02:33 - [INFO|feature_extraction_utils.py:377] 2023-09-07 11:02:33,120 >> Feature extractor saved in /mnt/output/checkpoint-650/preprocessor_config.json\n",
      "2023-09-07 11:05:30 - {'loss': 0.0001, 'learning_rate': 4.0875e-06, 'epoch': 42.86}\n",
      "2023-09-07 11:08:21 - {'loss': 0.0001, 'learning_rate': 3.7750000000000003e-06, 'epoch': 44.44}\n",
      "2023-09-07 11:08:39 - {'eval_loss': 0.7390508055686951, 'eval_wer': 0.15889628924833493, 'eval_runtime': 17.599, 'eval_samples_per_second': 3.125, 'eval_steps_per_second': 0.227, 'epoch': 44.44}\n",
      " 70% 700/1000 [1:26:03<34:22,  6.88s/it][INFO|trainer.py:776] 2023-09-07 11:08:21,611 >> The following columns in the evaluation set don't have a corresponding argument in `WhisperForConditionalGeneration.forward` and have been ignored: input_length. If input_length are not expected by `WhisperForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "2023-09-07 11:08:21 - [INFO|trainer.py:3200] 2023-09-07 11:08:21,612 >> ***** Running Evaluation *****\n",
      "2023-09-07 11:08:21 - [INFO|trainer.py:3205] 2023-09-07 11:08:21,612 >>   Batch size = 8\n",
      "2023-09-07 11:08:21 - [INFO|trainer.py:3202] 2023-09-07 11:08:21,612 >>   Num examples = 55\n",
      "2023-09-07 11:08:25 - \n",
      "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50% 2/4 [00:04<00:04,  2.01s/it]\u001b[A\n",
      " 75% 3/4 [00:08<00:03,  3.21s/it]\u001b[A\n",
      "                                        \n",
      "100% 4/4 [00:13<00:00,  3.62s/it]\u001b[A\n",
      "                                 \u001b[A[INFO|trainer.py:2926] 2023-09-07 11:08:39,213 >> Saving model checkpoint to /mnt/output/checkpoint-700\n",
      " 70% 700/1000 [1:26:21<34:22,  6.88s/it]\n",
      "2023-09-07 11:08:39 - [INFO|configuration_utils.py:364] 2023-09-07 11:08:39,215 >> Configuration saved in /mnt/output/checkpoint-700/generation_config.json\n",
      "2023-09-07 11:08:39 - [INFO|configuration_utils.py:458] 2023-09-07 11:08:39,214 >> Configuration saved in /mnt/output/checkpoint-700/config.json\n",
      "2023-09-07 11:08:41 - [INFO|modeling_utils.py:1853] 2023-09-07 11:08:41,840 >> Model weights saved in /mnt/output/checkpoint-700/pytorch_model.bin\n",
      "2023-09-07 11:08:41 - [INFO|feature_extraction_utils.py:377] 2023-09-07 11:08:41,841 >> Feature extractor saved in /mnt/output/checkpoint-700/preprocessor_config.json\n"
     ]
    }
   ],
   "source": [
    "job_run.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b86dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr cap\n",
    "job_run.watch()\n",
    "\n",
    "with open('output1000_atco2.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579ad37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
